{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jane0731/Homework/blob/main/%E9%87%91%E8%9E%8D%E5%A4%A7%E6%95%B8%E6%93%9A_W11.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 492
        },
        "id": "9sl7X3U7t-ZF",
        "outputId": "2abab657-8005-4c63-fb4b-7e4f253460c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.6.17)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.66.6)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.2.3)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.2.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.10)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-766bf164-86d9-43a5-a7fd-808fdbbe0e92\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-766bf164-86d9-43a5-a7fd-808fdbbe0e92\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n",
            "Downloading stock-market-prediction-and-sentimental-analysis.zip to /content\n",
            " 65% 4.00M/6.17M [00:01<00:00, 4.47MB/s]\n",
            "100% 6.17M/6.17M [00:01<00:00, 4.67MB/s]\n",
            "Archive:  stock-market-prediction-and-sentimental-analysis.zip\n",
            "  inflating: Combined_News_DJIA(train).csv  \n",
            "  inflating: DJIA_table(train).csv   \n",
            "  inflating: RedditNews(train).csv   \n",
            "  inflating: TEST_Redit_news.csv     \n",
            "  inflating: Test_Combined_News.csv  \n",
            "  inflating: Test_DJIA_Table.csv     \n",
            "  inflating: sample_submission.csv   \n"
          ]
        }
      ],
      "source": [
        "!pip install kaggle\n",
        "\n",
        "from google.colab import files\n",
        "files.upload()  # This will allow you to upload your kaggle.json\n",
        "\n",
        "import os\n",
        "os.makedirs('/root/.kaggle', exist_ok=True)\n",
        "!mv kaggle.json /root/.kaggle/\n",
        "\n",
        "!chmod 600 /root/.kaggle/kaggle.json\n",
        "\n",
        "!kaggle competitions download -c stock-market-prediction-and-sentimental-analysis\n",
        "\n",
        "!unzip stock-market-prediction-and-sentimental-analysis.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "_yVdy5YduAUC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "243ac0be-ba15-45d5-8cdf-9e525503aa4a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         Date                                               News\n",
            "0  2016-07-01  A 117-year-old woman in Mexico City finally re...\n",
            "1  2016-07-01   IMF chief backs Athens as permanent Olympic host\n",
            "2  2016-07-01  The president of France says if Brexit won, so...\n",
            "3  2016-07-01  British Man Who Must Give Police 24 Hours' Not...\n",
            "4  2016-07-01  100+ Nobel laureates urge Greenpeace to stop o...\n",
            "         Date         Open         High          Low        Close    Volume  \\\n",
            "0  31-12-2015  17590.66016  17590.66016  17421.16016  17425.02930  93690000   \n",
            "1  30-12-2015  17711.93945  17714.13086  17588.86914  17603.86914  59760000   \n",
            "2  29-12-2015  17547.36914  17750.01953  17547.36914  17720.98047  69860000   \n",
            "3  28-12-2015  17535.66016  17536.90039  17437.33984  17528.26953  59770000   \n",
            "4  24-12-2015  17593.25977  17606.33984  17543.94922  17552.16992  40350000   \n",
            "\n",
            "     Adj Close  \n",
            "0  17425.02930  \n",
            "1  17603.86914  \n",
            "2  17720.98047  \n",
            "3  17528.26953  \n",
            "4  17552.16992  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# 加載數據\n",
        "news_data = pd.read_csv(\"RedditNews(train).csv\")  # 包含日期和新聞標題\n",
        "stock_data = pd.read_csv(\"DJIA_table(train).csv\")  # 包含日期和股價數據\n",
        "\n",
        "print(news_data.head())\n",
        "print(stock_data.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Qm5ISt56uIhP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "outputId": "0e718015-9417-4189-bdc3-19f36ce32001"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "100%|██████████| 4601/4601 [02:21<00:00, 32.48it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             Date                                               News  \\\n",
              "0      2016-07-01  A 117-year-old woman in Mexico City finally re...   \n",
              "1      2016-07-01   IMF chief backs Athens as permanent Olympic host   \n",
              "2      2016-07-01  The president of France says if Brexit won, so...   \n",
              "3      2016-07-01  British Man Who Must Give Police 24 Hours' Not...   \n",
              "4      2016-07-01  100+ Nobel laureates urge Greenpeace to stop o...   \n",
              "...           ...                                                ...   \n",
              "73603  2008-06-08  b'Man goes berzerk in Akihabara and stabs ever...   \n",
              "73604  2008-06-08  b'Threat of world AIDS pandemic among heterose...   \n",
              "73605  2008-06-08  b'Angst in Ankara: Turkey Steers into a Danger...   \n",
              "73606  2008-06-08  b\"UK: Identity cards 'could be used to spy on ...   \n",
              "73607  2008-06-08  b'Marriage, they said, was reduced to the stat...   \n",
              "\n",
              "       Sentiment  \n",
              "0              1  \n",
              "1              1  \n",
              "2              1  \n",
              "3              1  \n",
              "4              1  \n",
              "...          ...  \n",
              "73603          1  \n",
              "73604          1  \n",
              "73605          1  \n",
              "73606          1  \n",
              "73607          1  \n",
              "\n",
              "[73608 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5a2c28f4-5616-4681-8f2f-137146521569\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>News</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2016-07-01</td>\n",
              "      <td>A 117-year-old woman in Mexico City finally re...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2016-07-01</td>\n",
              "      <td>IMF chief backs Athens as permanent Olympic host</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2016-07-01</td>\n",
              "      <td>The president of France says if Brexit won, so...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2016-07-01</td>\n",
              "      <td>British Man Who Must Give Police 24 Hours' Not...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2016-07-01</td>\n",
              "      <td>100+ Nobel laureates urge Greenpeace to stop o...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73603</th>\n",
              "      <td>2008-06-08</td>\n",
              "      <td>b'Man goes berzerk in Akihabara and stabs ever...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73604</th>\n",
              "      <td>2008-06-08</td>\n",
              "      <td>b'Threat of world AIDS pandemic among heterose...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73605</th>\n",
              "      <td>2008-06-08</td>\n",
              "      <td>b'Angst in Ankara: Turkey Steers into a Danger...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73606</th>\n",
              "      <td>2008-06-08</td>\n",
              "      <td>b\"UK: Identity cards 'could be used to spy on ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73607</th>\n",
              "      <td>2008-06-08</td>\n",
              "      <td>b'Marriage, they said, was reduced to the stat...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>73608 rows × 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5a2c28f4-5616-4681-8f2f-137146521569')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5a2c28f4-5616-4681-8f2f-137146521569 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5a2c28f4-5616-4681-8f2f-137146521569');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-929364bc-e683-4255-9d6a-97aeab502e30\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-929364bc-e683-4255-9d6a-97aeab502e30')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-929364bc-e683-4255-9d6a-97aeab502e30 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_23953187-309b-48b9-977c-07795a0d8ace\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('news_data')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_23953187-309b-48b9-977c-07795a0d8ace button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('news_data');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "news_data",
              "summary": "{\n  \"name\": \"news_data\",\n  \"rows\": 73608,\n  \"fields\": [\n    {\n      \"column\": \"Date\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 2943,\n        \"samples\": [\n          \"2014-03-13\",\n          \"2013-08-28\",\n          \"2009-12-04\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"News\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 73537,\n        \"samples\": [\n          \"Tens of thousands fill Rabin Square in Israel for anti-Netanyahu rally\",\n          \"b'Third in a series of of pipline explosions hits BC, Canada'\",\n          \"Man sentenced to death in Saudi Arabia will be crucified\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sentiment\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1,\n          0,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "\n",
        "# 啟用 GPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# 加載 DistilBERT 模型和分詞器\n",
        "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
        "model = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=3).to(device)\n",
        "\n",
        "# 批量處理新聞數據\n",
        "def analyze_sentiments_batch(headlines, batch_size=32):\n",
        "    sentiments = []\n",
        "    for i in tqdm(range(0, len(headlines), batch_size)):  # 使用進度條顯示\n",
        "        batch = headlines[i:i+batch_size]\n",
        "        inputs = tokenizer(batch, truncation=True, padding=True, max_length=128, return_tensors=\"pt\").to(device)\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "            batch_sentiments = torch.argmax(outputs.logits, dim=1).cpu().numpy()\n",
        "        sentiments.extend(batch_sentiments)\n",
        "    return sentiments\n",
        "\n",
        "\n",
        "# 分析新聞情緒\n",
        "news_data['Sentiment'] = analyze_sentiments_batch(news_data['News'].tolist(), batch_size=16)\n",
        "news_data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 計算每日情緒分佈\n",
        "sentiment_distribution = news_data.groupby(\"Date\")[\"Sentiment\"].value_counts(normalize=True).unstack(fill_value=0)\n",
        "\n",
        "# 重命名列（0: Negative, 1: Neutral, 2: Positive）\n",
        "sentiment_distribution.columns = [\"Negative\", \"Neutral\", \"Positive\"]\n",
        "sentiment_distribution.reset_index(inplace=True)\n",
        "\n",
        "# 查看每日情緒分佈\n",
        "print(sentiment_distribution.head())"
      ],
      "metadata": {
        "id": "VZXC5FUKvJd8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0eba308f-047c-431c-cda1-384f28231a7e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         Date  Negative  Neutral  Positive\n",
            "0  2008-06-08      0.04     0.96       0.0\n",
            "1  2008-06-09      0.08     0.92       0.0\n",
            "2  2008-06-10      0.00     1.00       0.0\n",
            "3  2008-06-11      0.12     0.88       0.0\n",
            "4  2008-06-12      0.04     0.96       0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "news_data['Date'] = pd.to_datetime(news_data['Date'])\n",
        "stock_data['Date'] = pd.to_datetime(stock_data['Date'])"
      ],
      "metadata": {
        "id": "70J8c4nt7a3u"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_data = pd.merge(stock_data, sentiment_distribution, on=\"Date\", how=\"inner\")\n",
        "merged_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "GhHVewGg6H-y",
        "outputId": "b48f87dd-e0d9-4bc3-e2bb-a9a7347df28b"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           Date         Open         High          Low        Close  \\\n",
              "0    2015-12-31  17590.66016  17590.66016  17421.16016  17425.02930   \n",
              "1    2015-12-30  17711.93945  17714.13086  17588.86914  17603.86914   \n",
              "2    2015-12-29  17547.36914  17750.01953  17547.36914  17720.98047   \n",
              "3    2015-12-28  17535.66016  17536.90039  17437.33984  17528.26953   \n",
              "4    2015-12-24  17593.25977  17606.33984  17543.94922  17552.16992   \n",
              "...         ...          ...          ...          ...          ...   \n",
              "1858 2008-08-14  11532.07031  11718.28027  11450.88965  11615.92969   \n",
              "1859 2008-08-13  11632.80957  11633.78027  11453.33984  11532.95996   \n",
              "1860 2008-08-12  11781.70020  11782.34961  11601.51953  11642.46973   \n",
              "1861 2008-08-11  11729.66992  11867.11035  11675.53027  11782.34961   \n",
              "1862 2008-08-08  11432.08984  11759.95996  11388.04004  11734.32031   \n",
              "\n",
              "         Volume    Adj Close  Negative  Neutral  Positive  \n",
              "0      93690000  17425.02930      0.16     0.84       0.0  \n",
              "1      59760000  17603.86914      0.28     0.72       0.0  \n",
              "2      69860000  17720.98047      0.20     0.80       0.0  \n",
              "3      59770000  17528.26953      0.24     0.76       0.0  \n",
              "4      40350000  17552.16992      0.28     0.72       0.0  \n",
              "...         ...          ...       ...      ...       ...  \n",
              "1858  159790000  11615.92969      0.04     0.96       0.0  \n",
              "1859  182550000  11532.95996      0.08     0.92       0.0  \n",
              "1860  173590000  11642.46973      0.08     0.92       0.0  \n",
              "1861  183190000  11782.34961      0.00     1.00       0.0  \n",
              "1862  212830000  11734.32031      0.08     0.92       0.0  \n",
              "\n",
              "[1863 rows x 10 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bbaa8d01-ddaa-4451-9c90-c1abe2dc2812\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Negative</th>\n",
              "      <th>Neutral</th>\n",
              "      <th>Positive</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2015-12-31</td>\n",
              "      <td>17590.66016</td>\n",
              "      <td>17590.66016</td>\n",
              "      <td>17421.16016</td>\n",
              "      <td>17425.02930</td>\n",
              "      <td>93690000</td>\n",
              "      <td>17425.02930</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.84</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2015-12-30</td>\n",
              "      <td>17711.93945</td>\n",
              "      <td>17714.13086</td>\n",
              "      <td>17588.86914</td>\n",
              "      <td>17603.86914</td>\n",
              "      <td>59760000</td>\n",
              "      <td>17603.86914</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0.72</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2015-12-29</td>\n",
              "      <td>17547.36914</td>\n",
              "      <td>17750.01953</td>\n",
              "      <td>17547.36914</td>\n",
              "      <td>17720.98047</td>\n",
              "      <td>69860000</td>\n",
              "      <td>17720.98047</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.80</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2015-12-28</td>\n",
              "      <td>17535.66016</td>\n",
              "      <td>17536.90039</td>\n",
              "      <td>17437.33984</td>\n",
              "      <td>17528.26953</td>\n",
              "      <td>59770000</td>\n",
              "      <td>17528.26953</td>\n",
              "      <td>0.24</td>\n",
              "      <td>0.76</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2015-12-24</td>\n",
              "      <td>17593.25977</td>\n",
              "      <td>17606.33984</td>\n",
              "      <td>17543.94922</td>\n",
              "      <td>17552.16992</td>\n",
              "      <td>40350000</td>\n",
              "      <td>17552.16992</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0.72</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1858</th>\n",
              "      <td>2008-08-14</td>\n",
              "      <td>11532.07031</td>\n",
              "      <td>11718.28027</td>\n",
              "      <td>11450.88965</td>\n",
              "      <td>11615.92969</td>\n",
              "      <td>159790000</td>\n",
              "      <td>11615.92969</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.96</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1859</th>\n",
              "      <td>2008-08-13</td>\n",
              "      <td>11632.80957</td>\n",
              "      <td>11633.78027</td>\n",
              "      <td>11453.33984</td>\n",
              "      <td>11532.95996</td>\n",
              "      <td>182550000</td>\n",
              "      <td>11532.95996</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.92</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1860</th>\n",
              "      <td>2008-08-12</td>\n",
              "      <td>11781.70020</td>\n",
              "      <td>11782.34961</td>\n",
              "      <td>11601.51953</td>\n",
              "      <td>11642.46973</td>\n",
              "      <td>173590000</td>\n",
              "      <td>11642.46973</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.92</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1861</th>\n",
              "      <td>2008-08-11</td>\n",
              "      <td>11729.66992</td>\n",
              "      <td>11867.11035</td>\n",
              "      <td>11675.53027</td>\n",
              "      <td>11782.34961</td>\n",
              "      <td>183190000</td>\n",
              "      <td>11782.34961</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1862</th>\n",
              "      <td>2008-08-08</td>\n",
              "      <td>11432.08984</td>\n",
              "      <td>11759.95996</td>\n",
              "      <td>11388.04004</td>\n",
              "      <td>11734.32031</td>\n",
              "      <td>212830000</td>\n",
              "      <td>11734.32031</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.92</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1863 rows × 10 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bbaa8d01-ddaa-4451-9c90-c1abe2dc2812')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-bbaa8d01-ddaa-4451-9c90-c1abe2dc2812 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-bbaa8d01-ddaa-4451-9c90-c1abe2dc2812');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-52f6ba57-bf73-430e-baee-9f8d59e166d3\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-52f6ba57-bf73-430e-baee-9f8d59e166d3')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-52f6ba57-bf73-430e-baee-9f8d59e166d3 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_a6b54108-4948-4154-aae9-e93c01ad4e59\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('merged_data')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_a6b54108-4948-4154-aae9-e93c01ad4e59 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('merged_data');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "merged_data",
              "summary": "{\n  \"name\": \"merged_data\",\n  \"rows\": 1863,\n  \"fields\": [\n    {\n      \"column\": \"Date\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2008-08-08 00:00:00\",\n        \"max\": \"2015-12-31 00:00:00\",\n        \"num_unique_values\": 1863,\n        \"samples\": [\n          \"2015-01-29 00:00:00\",\n          \"2013-11-21 00:00:00\",\n          \"2011-02-25 00:00:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Open\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3080.6336376733743,\n        \"min\": 6547.009766,\n        \"max\": 18315.06055,\n        \"num_unique_values\": 1855,\n        \"samples\": [\n          17402.91016,\n          16066.37012,\n          11860.11035\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"High\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3072.306028510614,\n        \"min\": 6709.609863,\n        \"max\": 18351.35938,\n        \"num_unique_values\": 1857,\n        \"samples\": [\n          17433.13086,\n          16363.32031,\n          11927.08984\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Low\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3089.8390320608414,\n        \"min\": 6469.950195,\n        \"max\": 18272.56055,\n        \"num_unique_values\": 1854,\n        \"samples\": [\n          17136.30078,\n          16245.92969,\n          11798.45996\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Close\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3081.319402247955,\n        \"min\": 6547.049805,\n        \"max\": 18312.39063,\n        \"num_unique_values\": 1852,\n        \"samples\": [\n          17191.36914,\n          16247.21973,\n          11787.37988\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Volume\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 95571871,\n        \"min\": 8410000,\n        \"max\": 674920000,\n        \"num_unique_values\": 1787,\n        \"samples\": [\n          106540000,\n          115660000,\n          201480000\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Adj Close\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3081.319402247955,\n        \"min\": 6547.049805,\n        \"max\": 18312.39063,\n        \"num_unique_values\": 1852,\n        \"samples\": [\n          17191.36914,\n          16247.21973,\n          11787.37988\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Negative\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.08386587923420578,\n        \"min\": 0.0,\n        \"max\": 0.48,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.32,\n          0.4,\n          0.16\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Neutral\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.08386587923420592,\n        \"min\": 0.52,\n        \"max\": 1.0,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.68,\n          0.6,\n          0.84\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Positive\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.0,\n        \"max\": 0.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "import torch\n",
        "\n",
        "# 股票數據特徵\n",
        "stock_features = merged_data[['Open', 'High', 'Low', 'Close', 'Volume']].values\n",
        "scaler = StandardScaler()\n",
        "stock_features = scaler.fit_transform(stock_features)\n",
        "\n",
        "# 新聞情緒特徵\n",
        "sentiment_features = merged_data[['Negative', 'Neutral', 'Positive']].values\n",
        "\n",
        "# 漲跌標籤（1: 漲, 0: 跌）\n",
        "labels = (merged_data['Close'].shift(-1) > merged_data['Close']).astype(int).values[:-1]\n",
        "\n",
        "# 去掉最後一行，因為沒有標籤\n",
        "stock_features = stock_features[:-1]\n",
        "sentiment_features = sentiment_features[:-1]\n",
        "\n",
        "# 轉為 Tensor\n",
        "stock_features = torch.tensor(stock_features, dtype=torch.float32)\n",
        "sentiment_features = torch.tensor(sentiment_features, dtype=torch.float32)\n",
        "labels = torch.tensor(labels, dtype=torch.long)\n"
      ],
      "metadata": {
        "id": "DWq6eHAF6JCW"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class StockModel(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "        super(StockModel, self).__init__()\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(input_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, output_dim),\n",
        "            nn.Softmax(dim=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.fc(x)\n",
        "\n",
        "# 股票數據模型\n",
        "stock_model = StockModel(input_dim=5, hidden_dim=64, output_dim=2)  # 5 個股價特徵，2 類別"
      ],
      "metadata": {
        "id": "TZ62yBAs8jt1"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LateFusionModel(nn.Module):\n",
        "    def __init__(self, stock_model, sentiment_weight=0.5):\n",
        "        super(LateFusionModel, self).__init__()\n",
        "        self.stock_model = stock_model\n",
        "        self.sentiment_weight = sentiment_weight\n",
        "\n",
        "    def forward(self, stock_features, sentiment_probs):\n",
        "        # 股票模型預測\n",
        "        stock_probs = self.stock_model(stock_features)\n",
        "        # 提取新聞情緒的 Positive 和 Negative 概率，忽略 Neutral\n",
        "        sentiment_probs = sentiment_probs[:, [0, 2]]  # 第 0 列是 Negative，第 2 列是 Positive\n",
        "\n",
        "        # 融合預測\n",
        "        final_probs = stock_probs * (1 - self.sentiment_weight) + sentiment_probs * self.sentiment_weight\n",
        "        return final_probs"
      ],
      "metadata": {
        "id": "untSGmM88lKE"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 分割股票數據\n",
        "train_stock, val_stock, train_sentiments, val_sentiments, train_labels, val_labels = train_test_split(\n",
        "    stock_features, sentiment_features, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# 將數據轉為 Tensor\n",
        "train_stock = torch.tensor(train_stock, dtype=torch.float32)\n",
        "val_stock = torch.tensor(val_stock, dtype=torch.float32)\n",
        "train_sentiment = torch.tensor(train_sentiments, dtype=torch.float32)\n",
        "val_sentiment = torch.tensor(val_sentiments, dtype=torch.float32)\n",
        "train_labels = torch.tensor(train_labels, dtype=torch.long)\n",
        "val_labels = torch.tensor(val_labels, dtype=torch.long)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HSvhdCga8mPH",
        "outputId": "8a29b8f6-35a4-479a-8133-135a06484a75"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-26-4283fc0c2616>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  train_stock = torch.tensor(train_stock, dtype=torch.float32)\n",
            "<ipython-input-26-4283fc0c2616>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  val_stock = torch.tensor(val_stock, dtype=torch.float32)\n",
            "<ipython-input-26-4283fc0c2616>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  train_sentiment = torch.tensor(train_sentiments, dtype=torch.float32)\n",
            "<ipython-input-26-4283fc0c2616>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  val_sentiment = torch.tensor(val_sentiments, dtype=torch.float32)\n",
            "<ipython-input-26-4283fc0c2616>:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  train_labels = torch.tensor(train_labels, dtype=torch.long)\n",
            "<ipython-input-26-4283fc0c2616>:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  val_labels = torch.tensor(val_labels, dtype=torch.long)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, stock_inputs, sentiment_inputs, labels, optimizer, criterion, epochs=500):\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # 模型預測\n",
        "        outputs = model(stock_inputs, sentiment_inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        print(f\"Epoch {epoch + 1}/{epochs}, Loss: {loss.item():.4f}\")"
      ],
      "metadata": {
        "id": "1hkudlsd8nXP"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 初始化晚期融合模型\n",
        "fusion_model = LateFusionModel(stock_model, sentiment_weight=0.5)\n",
        "\n",
        "# 定義優化器和損失函數\n",
        "optimizer = torch.optim.Adam(fusion_model.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()\n"
      ],
      "metadata": {
        "id": "rnXOFRQf8oZJ"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 修改訓練函數以記錄歷史數據\n",
        "def train_model_with_logs(model, stock_inputs, sentiment_inputs, labels, val_stock, val_sentiments, val_labels, optimizer, criterion, epochs=1000):\n",
        "    train_losses = []\n",
        "    val_accuracies = []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # 訓練階段\n",
        "        outputs = model(stock_inputs, sentiment_inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # 記錄訓練損失\n",
        "        train_losses.append(loss.item())\n",
        "\n",
        "        # 驗證階段\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            val_outputs = model(val_stock, val_sentiments)\n",
        "            val_preds = torch.argmax(val_outputs, dim=1).cpu().numpy()\n",
        "            val_true_labels = val_labels.cpu().numpy()\n",
        "            val_accuracy = (val_preds == val_true_labels).mean()\n",
        "\n",
        "        # 記錄驗證準確率\n",
        "        val_accuracies.append(val_accuracy)\n",
        "\n",
        "        print(f\"Epoch {epoch + 1}/{epochs}, Loss: {loss.item():.4f}, Val Accuracy: {val_accuracy:.4f}\")\n",
        "\n",
        "    return train_losses, val_accuracies\n",
        "\n",
        "# 訓練模型並記錄歷史數據\n",
        "train_losses, val_accuracies = train_model_with_logs(\n",
        "    fusion_model, train_stock, train_sentiments, train_labels,\n",
        "    val_stock, val_sentiment, val_labels, optimizer, criterion\n",
        ")\n",
        "\n",
        "# 繪製曲線\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(train_losses, label=\"Training Loss\")\n",
        "plt.plot(val_accuracies, label=\"Validation Accuracy\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Value\")\n",
        "plt.title(\"Training Loss and Validation Accuracy over Epochs\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "N0wPaCiH8pdM",
        "outputId": "bfa53bf2-f2c5-45b4-f392-9e65bd2544b9"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000, Loss: 0.5063, Val Accuracy: 0.9571\n",
            "Epoch 2/1000, Loss: 0.5063, Val Accuracy: 0.9544\n",
            "Epoch 3/1000, Loss: 0.5062, Val Accuracy: 0.9544\n",
            "Epoch 4/1000, Loss: 0.5062, Val Accuracy: 0.9544\n",
            "Epoch 5/1000, Loss: 0.5062, Val Accuracy: 0.9544\n",
            "Epoch 6/1000, Loss: 0.5062, Val Accuracy: 0.9544\n",
            "Epoch 7/1000, Loss: 0.5062, Val Accuracy: 0.9544\n",
            "Epoch 8/1000, Loss: 0.5062, Val Accuracy: 0.9571\n",
            "Epoch 9/1000, Loss: 0.5061, Val Accuracy: 0.9544\n",
            "Epoch 10/1000, Loss: 0.5061, Val Accuracy: 0.9571\n",
            "Epoch 11/1000, Loss: 0.5061, Val Accuracy: 0.9544\n",
            "Epoch 12/1000, Loss: 0.5061, Val Accuracy: 0.9571\n",
            "Epoch 13/1000, Loss: 0.5061, Val Accuracy: 0.9544\n",
            "Epoch 14/1000, Loss: 0.5061, Val Accuracy: 0.9544\n",
            "Epoch 15/1000, Loss: 0.5061, Val Accuracy: 0.9544\n",
            "Epoch 16/1000, Loss: 0.5060, Val Accuracy: 0.9544\n",
            "Epoch 17/1000, Loss: 0.5060, Val Accuracy: 0.9544\n",
            "Epoch 18/1000, Loss: 0.5060, Val Accuracy: 0.9544\n",
            "Epoch 19/1000, Loss: 0.5060, Val Accuracy: 0.9544\n",
            "Epoch 20/1000, Loss: 0.5060, Val Accuracy: 0.9544\n",
            "Epoch 21/1000, Loss: 0.5060, Val Accuracy: 0.9571\n",
            "Epoch 22/1000, Loss: 0.5060, Val Accuracy: 0.9544\n",
            "Epoch 23/1000, Loss: 0.5060, Val Accuracy: 0.9571\n",
            "Epoch 24/1000, Loss: 0.5059, Val Accuracy: 0.9544\n",
            "Epoch 25/1000, Loss: 0.5059, Val Accuracy: 0.9571\n",
            "Epoch 26/1000, Loss: 0.5059, Val Accuracy: 0.9544\n",
            "Epoch 27/1000, Loss: 0.5059, Val Accuracy: 0.9544\n",
            "Epoch 28/1000, Loss: 0.5059, Val Accuracy: 0.9544\n",
            "Epoch 29/1000, Loss: 0.5059, Val Accuracy: 0.9571\n",
            "Epoch 30/1000, Loss: 0.5059, Val Accuracy: 0.9544\n",
            "Epoch 31/1000, Loss: 0.5058, Val Accuracy: 0.9571\n",
            "Epoch 32/1000, Loss: 0.5058, Val Accuracy: 0.9544\n",
            "Epoch 33/1000, Loss: 0.5058, Val Accuracy: 0.9571\n",
            "Epoch 34/1000, Loss: 0.5058, Val Accuracy: 0.9571\n",
            "Epoch 35/1000, Loss: 0.5058, Val Accuracy: 0.9571\n",
            "Epoch 36/1000, Loss: 0.5058, Val Accuracy: 0.9571\n",
            "Epoch 37/1000, Loss: 0.5058, Val Accuracy: 0.9571\n",
            "Epoch 38/1000, Loss: 0.5057, Val Accuracy: 0.9571\n",
            "Epoch 39/1000, Loss: 0.5057, Val Accuracy: 0.9571\n",
            "Epoch 40/1000, Loss: 0.5057, Val Accuracy: 0.9571\n",
            "Epoch 41/1000, Loss: 0.5057, Val Accuracy: 0.9571\n",
            "Epoch 42/1000, Loss: 0.5057, Val Accuracy: 0.9571\n",
            "Epoch 43/1000, Loss: 0.5057, Val Accuracy: 0.9571\n",
            "Epoch 44/1000, Loss: 0.5057, Val Accuracy: 0.9571\n",
            "Epoch 45/1000, Loss: 0.5056, Val Accuracy: 0.9571\n",
            "Epoch 46/1000, Loss: 0.5056, Val Accuracy: 0.9571\n",
            "Epoch 47/1000, Loss: 0.5056, Val Accuracy: 0.9571\n",
            "Epoch 48/1000, Loss: 0.5056, Val Accuracy: 0.9571\n",
            "Epoch 49/1000, Loss: 0.5056, Val Accuracy: 0.9571\n",
            "Epoch 50/1000, Loss: 0.5056, Val Accuracy: 0.9571\n",
            "Epoch 51/1000, Loss: 0.5056, Val Accuracy: 0.9571\n",
            "Epoch 52/1000, Loss: 0.5056, Val Accuracy: 0.9571\n",
            "Epoch 53/1000, Loss: 0.5055, Val Accuracy: 0.9571\n",
            "Epoch 54/1000, Loss: 0.5055, Val Accuracy: 0.9571\n",
            "Epoch 55/1000, Loss: 0.5055, Val Accuracy: 0.9571\n",
            "Epoch 56/1000, Loss: 0.5055, Val Accuracy: 0.9544\n",
            "Epoch 57/1000, Loss: 0.5055, Val Accuracy: 0.9571\n",
            "Epoch 58/1000, Loss: 0.5055, Val Accuracy: 0.9544\n",
            "Epoch 59/1000, Loss: 0.5055, Val Accuracy: 0.9571\n",
            "Epoch 60/1000, Loss: 0.5054, Val Accuracy: 0.9544\n",
            "Epoch 61/1000, Loss: 0.5054, Val Accuracy: 0.9571\n",
            "Epoch 62/1000, Loss: 0.5054, Val Accuracy: 0.9571\n",
            "Epoch 63/1000, Loss: 0.5054, Val Accuracy: 0.9571\n",
            "Epoch 64/1000, Loss: 0.5054, Val Accuracy: 0.9571\n",
            "Epoch 65/1000, Loss: 0.5054, Val Accuracy: 0.9571\n",
            "Epoch 66/1000, Loss: 0.5054, Val Accuracy: 0.9571\n",
            "Epoch 67/1000, Loss: 0.5054, Val Accuracy: 0.9571\n",
            "Epoch 68/1000, Loss: 0.5053, Val Accuracy: 0.9571\n",
            "Epoch 69/1000, Loss: 0.5053, Val Accuracy: 0.9571\n",
            "Epoch 70/1000, Loss: 0.5053, Val Accuracy: 0.9571\n",
            "Epoch 71/1000, Loss: 0.5053, Val Accuracy: 0.9571\n",
            "Epoch 72/1000, Loss: 0.5053, Val Accuracy: 0.9571\n",
            "Epoch 73/1000, Loss: 0.5053, Val Accuracy: 0.9571\n",
            "Epoch 74/1000, Loss: 0.5053, Val Accuracy: 0.9571\n",
            "Epoch 75/1000, Loss: 0.5052, Val Accuracy: 0.9571\n",
            "Epoch 76/1000, Loss: 0.5052, Val Accuracy: 0.9544\n",
            "Epoch 77/1000, Loss: 0.5052, Val Accuracy: 0.9571\n",
            "Epoch 78/1000, Loss: 0.5052, Val Accuracy: 0.9571\n",
            "Epoch 79/1000, Loss: 0.5052, Val Accuracy: 0.9571\n",
            "Epoch 80/1000, Loss: 0.5052, Val Accuracy: 0.9571\n",
            "Epoch 81/1000, Loss: 0.5052, Val Accuracy: 0.9571\n",
            "Epoch 82/1000, Loss: 0.5051, Val Accuracy: 0.9571\n",
            "Epoch 83/1000, Loss: 0.5051, Val Accuracy: 0.9571\n",
            "Epoch 84/1000, Loss: 0.5051, Val Accuracy: 0.9571\n",
            "Epoch 85/1000, Loss: 0.5051, Val Accuracy: 0.9571\n",
            "Epoch 86/1000, Loss: 0.5051, Val Accuracy: 0.9571\n",
            "Epoch 87/1000, Loss: 0.5051, Val Accuracy: 0.9571\n",
            "Epoch 88/1000, Loss: 0.5051, Val Accuracy: 0.9571\n",
            "Epoch 89/1000, Loss: 0.5051, Val Accuracy: 0.9571\n",
            "Epoch 90/1000, Loss: 0.5050, Val Accuracy: 0.9571\n",
            "Epoch 91/1000, Loss: 0.5050, Val Accuracy: 0.9571\n",
            "Epoch 92/1000, Loss: 0.5050, Val Accuracy: 0.9571\n",
            "Epoch 93/1000, Loss: 0.5050, Val Accuracy: 0.9571\n",
            "Epoch 94/1000, Loss: 0.5050, Val Accuracy: 0.9571\n",
            "Epoch 95/1000, Loss: 0.5050, Val Accuracy: 0.9571\n",
            "Epoch 96/1000, Loss: 0.5050, Val Accuracy: 0.9571\n",
            "Epoch 97/1000, Loss: 0.5050, Val Accuracy: 0.9571\n",
            "Epoch 98/1000, Loss: 0.5049, Val Accuracy: 0.9571\n",
            "Epoch 99/1000, Loss: 0.5049, Val Accuracy: 0.9571\n",
            "Epoch 100/1000, Loss: 0.5049, Val Accuracy: 0.9571\n",
            "Epoch 101/1000, Loss: 0.5049, Val Accuracy: 0.9571\n",
            "Epoch 102/1000, Loss: 0.5049, Val Accuracy: 0.9571\n",
            "Epoch 103/1000, Loss: 0.5049, Val Accuracy: 0.9571\n",
            "Epoch 104/1000, Loss: 0.5049, Val Accuracy: 0.9571\n",
            "Epoch 105/1000, Loss: 0.5049, Val Accuracy: 0.9571\n",
            "Epoch 106/1000, Loss: 0.5048, Val Accuracy: 0.9598\n",
            "Epoch 107/1000, Loss: 0.5048, Val Accuracy: 0.9571\n",
            "Epoch 108/1000, Loss: 0.5048, Val Accuracy: 0.9571\n",
            "Epoch 109/1000, Loss: 0.5048, Val Accuracy: 0.9571\n",
            "Epoch 110/1000, Loss: 0.5048, Val Accuracy: 0.9571\n",
            "Epoch 111/1000, Loss: 0.5048, Val Accuracy: 0.9571\n",
            "Epoch 112/1000, Loss: 0.5048, Val Accuracy: 0.9598\n",
            "Epoch 113/1000, Loss: 0.5047, Val Accuracy: 0.9571\n",
            "Epoch 114/1000, Loss: 0.5047, Val Accuracy: 0.9598\n",
            "Epoch 115/1000, Loss: 0.5047, Val Accuracy: 0.9571\n",
            "Epoch 116/1000, Loss: 0.5047, Val Accuracy: 0.9571\n",
            "Epoch 117/1000, Loss: 0.5047, Val Accuracy: 0.9571\n",
            "Epoch 118/1000, Loss: 0.5047, Val Accuracy: 0.9571\n",
            "Epoch 119/1000, Loss: 0.5047, Val Accuracy: 0.9571\n",
            "Epoch 120/1000, Loss: 0.5047, Val Accuracy: 0.9571\n",
            "Epoch 121/1000, Loss: 0.5046, Val Accuracy: 0.9571\n",
            "Epoch 122/1000, Loss: 0.5046, Val Accuracy: 0.9571\n",
            "Epoch 123/1000, Loss: 0.5046, Val Accuracy: 0.9571\n",
            "Epoch 124/1000, Loss: 0.5046, Val Accuracy: 0.9571\n",
            "Epoch 125/1000, Loss: 0.5046, Val Accuracy: 0.9571\n",
            "Epoch 126/1000, Loss: 0.5046, Val Accuracy: 0.9571\n",
            "Epoch 127/1000, Loss: 0.5046, Val Accuracy: 0.9571\n",
            "Epoch 128/1000, Loss: 0.5046, Val Accuracy: 0.9571\n",
            "Epoch 129/1000, Loss: 0.5045, Val Accuracy: 0.9571\n",
            "Epoch 130/1000, Loss: 0.5045, Val Accuracy: 0.9571\n",
            "Epoch 131/1000, Loss: 0.5045, Val Accuracy: 0.9571\n",
            "Epoch 132/1000, Loss: 0.5045, Val Accuracy: 0.9571\n",
            "Epoch 133/1000, Loss: 0.5045, Val Accuracy: 0.9571\n",
            "Epoch 134/1000, Loss: 0.5045, Val Accuracy: 0.9598\n",
            "Epoch 135/1000, Loss: 0.5045, Val Accuracy: 0.9571\n",
            "Epoch 136/1000, Loss: 0.5045, Val Accuracy: 0.9598\n",
            "Epoch 137/1000, Loss: 0.5044, Val Accuracy: 0.9571\n",
            "Epoch 138/1000, Loss: 0.5044, Val Accuracy: 0.9571\n",
            "Epoch 139/1000, Loss: 0.5044, Val Accuracy: 0.9598\n",
            "Epoch 140/1000, Loss: 0.5044, Val Accuracy: 0.9571\n",
            "Epoch 141/1000, Loss: 0.5044, Val Accuracy: 0.9598\n",
            "Epoch 142/1000, Loss: 0.5044, Val Accuracy: 0.9571\n",
            "Epoch 143/1000, Loss: 0.5044, Val Accuracy: 0.9598\n",
            "Epoch 144/1000, Loss: 0.5044, Val Accuracy: 0.9571\n",
            "Epoch 145/1000, Loss: 0.5044, Val Accuracy: 0.9571\n",
            "Epoch 146/1000, Loss: 0.5043, Val Accuracy: 0.9571\n",
            "Epoch 147/1000, Loss: 0.5043, Val Accuracy: 0.9571\n",
            "Epoch 148/1000, Loss: 0.5043, Val Accuracy: 0.9598\n",
            "Epoch 149/1000, Loss: 0.5043, Val Accuracy: 0.9571\n",
            "Epoch 150/1000, Loss: 0.5043, Val Accuracy: 0.9571\n",
            "Epoch 151/1000, Loss: 0.5043, Val Accuracy: 0.9598\n",
            "Epoch 152/1000, Loss: 0.5043, Val Accuracy: 0.9571\n",
            "Epoch 153/1000, Loss: 0.5042, Val Accuracy: 0.9598\n",
            "Epoch 154/1000, Loss: 0.5042, Val Accuracy: 0.9571\n",
            "Epoch 155/1000, Loss: 0.5042, Val Accuracy: 0.9598\n",
            "Epoch 156/1000, Loss: 0.5042, Val Accuracy: 0.9571\n",
            "Epoch 157/1000, Loss: 0.5042, Val Accuracy: 0.9598\n",
            "Epoch 158/1000, Loss: 0.5042, Val Accuracy: 0.9571\n",
            "Epoch 159/1000, Loss: 0.5042, Val Accuracy: 0.9598\n",
            "Epoch 160/1000, Loss: 0.5042, Val Accuracy: 0.9571\n",
            "Epoch 161/1000, Loss: 0.5041, Val Accuracy: 0.9598\n",
            "Epoch 162/1000, Loss: 0.5041, Val Accuracy: 0.9571\n",
            "Epoch 163/1000, Loss: 0.5041, Val Accuracy: 0.9598\n",
            "Epoch 164/1000, Loss: 0.5041, Val Accuracy: 0.9571\n",
            "Epoch 165/1000, Loss: 0.5041, Val Accuracy: 0.9598\n",
            "Epoch 166/1000, Loss: 0.5041, Val Accuracy: 0.9571\n",
            "Epoch 167/1000, Loss: 0.5041, Val Accuracy: 0.9571\n",
            "Epoch 168/1000, Loss: 0.5041, Val Accuracy: 0.9598\n",
            "Epoch 169/1000, Loss: 0.5040, Val Accuracy: 0.9571\n",
            "Epoch 170/1000, Loss: 0.5040, Val Accuracy: 0.9598\n",
            "Epoch 171/1000, Loss: 0.5040, Val Accuracy: 0.9571\n",
            "Epoch 172/1000, Loss: 0.5040, Val Accuracy: 0.9598\n",
            "Epoch 173/1000, Loss: 0.5040, Val Accuracy: 0.9571\n",
            "Epoch 174/1000, Loss: 0.5040, Val Accuracy: 0.9598\n",
            "Epoch 175/1000, Loss: 0.5040, Val Accuracy: 0.9571\n",
            "Epoch 176/1000, Loss: 0.5040, Val Accuracy: 0.9598\n",
            "Epoch 177/1000, Loss: 0.5039, Val Accuracy: 0.9571\n",
            "Epoch 178/1000, Loss: 0.5039, Val Accuracy: 0.9598\n",
            "Epoch 179/1000, Loss: 0.5039, Val Accuracy: 0.9571\n",
            "Epoch 180/1000, Loss: 0.5039, Val Accuracy: 0.9598\n",
            "Epoch 181/1000, Loss: 0.5039, Val Accuracy: 0.9571\n",
            "Epoch 182/1000, Loss: 0.5039, Val Accuracy: 0.9598\n",
            "Epoch 183/1000, Loss: 0.5039, Val Accuracy: 0.9571\n",
            "Epoch 184/1000, Loss: 0.5039, Val Accuracy: 0.9598\n",
            "Epoch 185/1000, Loss: 0.5039, Val Accuracy: 0.9571\n",
            "Epoch 186/1000, Loss: 0.5038, Val Accuracy: 0.9598\n",
            "Epoch 187/1000, Loss: 0.5038, Val Accuracy: 0.9571\n",
            "Epoch 188/1000, Loss: 0.5038, Val Accuracy: 0.9598\n",
            "Epoch 189/1000, Loss: 0.5038, Val Accuracy: 0.9571\n",
            "Epoch 190/1000, Loss: 0.5038, Val Accuracy: 0.9598\n",
            "Epoch 191/1000, Loss: 0.5038, Val Accuracy: 0.9571\n",
            "Epoch 192/1000, Loss: 0.5038, Val Accuracy: 0.9598\n",
            "Epoch 193/1000, Loss: 0.5038, Val Accuracy: 0.9571\n",
            "Epoch 194/1000, Loss: 0.5037, Val Accuracy: 0.9598\n",
            "Epoch 195/1000, Loss: 0.5037, Val Accuracy: 0.9571\n",
            "Epoch 196/1000, Loss: 0.5037, Val Accuracy: 0.9598\n",
            "Epoch 197/1000, Loss: 0.5037, Val Accuracy: 0.9571\n",
            "Epoch 198/1000, Loss: 0.5037, Val Accuracy: 0.9598\n",
            "Epoch 199/1000, Loss: 0.5037, Val Accuracy: 0.9571\n",
            "Epoch 200/1000, Loss: 0.5037, Val Accuracy: 0.9598\n",
            "Epoch 201/1000, Loss: 0.5037, Val Accuracy: 0.9571\n",
            "Epoch 202/1000, Loss: 0.5036, Val Accuracy: 0.9598\n",
            "Epoch 203/1000, Loss: 0.5036, Val Accuracy: 0.9571\n",
            "Epoch 204/1000, Loss: 0.5036, Val Accuracy: 0.9598\n",
            "Epoch 205/1000, Loss: 0.5036, Val Accuracy: 0.9571\n",
            "Epoch 206/1000, Loss: 0.5036, Val Accuracy: 0.9598\n",
            "Epoch 207/1000, Loss: 0.5036, Val Accuracy: 0.9598\n",
            "Epoch 208/1000, Loss: 0.5036, Val Accuracy: 0.9598\n",
            "Epoch 209/1000, Loss: 0.5036, Val Accuracy: 0.9598\n",
            "Epoch 210/1000, Loss: 0.5036, Val Accuracy: 0.9598\n",
            "Epoch 211/1000, Loss: 0.5035, Val Accuracy: 0.9571\n",
            "Epoch 212/1000, Loss: 0.5035, Val Accuracy: 0.9598\n",
            "Epoch 213/1000, Loss: 0.5035, Val Accuracy: 0.9571\n",
            "Epoch 214/1000, Loss: 0.5035, Val Accuracy: 0.9598\n",
            "Epoch 215/1000, Loss: 0.5035, Val Accuracy: 0.9571\n",
            "Epoch 216/1000, Loss: 0.5035, Val Accuracy: 0.9598\n",
            "Epoch 217/1000, Loss: 0.5035, Val Accuracy: 0.9571\n",
            "Epoch 218/1000, Loss: 0.5035, Val Accuracy: 0.9598\n",
            "Epoch 219/1000, Loss: 0.5034, Val Accuracy: 0.9571\n",
            "Epoch 220/1000, Loss: 0.5034, Val Accuracy: 0.9598\n",
            "Epoch 221/1000, Loss: 0.5034, Val Accuracy: 0.9571\n",
            "Epoch 222/1000, Loss: 0.5034, Val Accuracy: 0.9598\n",
            "Epoch 223/1000, Loss: 0.5034, Val Accuracy: 0.9571\n",
            "Epoch 224/1000, Loss: 0.5034, Val Accuracy: 0.9598\n",
            "Epoch 225/1000, Loss: 0.5034, Val Accuracy: 0.9598\n",
            "Epoch 226/1000, Loss: 0.5034, Val Accuracy: 0.9598\n",
            "Epoch 227/1000, Loss: 0.5034, Val Accuracy: 0.9598\n",
            "Epoch 228/1000, Loss: 0.5033, Val Accuracy: 0.9598\n",
            "Epoch 229/1000, Loss: 0.5033, Val Accuracy: 0.9571\n",
            "Epoch 230/1000, Loss: 0.5033, Val Accuracy: 0.9598\n",
            "Epoch 231/1000, Loss: 0.5033, Val Accuracy: 0.9571\n",
            "Epoch 232/1000, Loss: 0.5033, Val Accuracy: 0.9598\n",
            "Epoch 233/1000, Loss: 0.5033, Val Accuracy: 0.9598\n",
            "Epoch 234/1000, Loss: 0.5033, Val Accuracy: 0.9598\n",
            "Epoch 235/1000, Loss: 0.5033, Val Accuracy: 0.9571\n",
            "Epoch 236/1000, Loss: 0.5032, Val Accuracy: 0.9598\n",
            "Epoch 237/1000, Loss: 0.5032, Val Accuracy: 0.9571\n",
            "Epoch 238/1000, Loss: 0.5032, Val Accuracy: 0.9598\n",
            "Epoch 239/1000, Loss: 0.5032, Val Accuracy: 0.9571\n",
            "Epoch 240/1000, Loss: 0.5032, Val Accuracy: 0.9598\n",
            "Epoch 241/1000, Loss: 0.5032, Val Accuracy: 0.9598\n",
            "Epoch 242/1000, Loss: 0.5032, Val Accuracy: 0.9598\n",
            "Epoch 243/1000, Loss: 0.5032, Val Accuracy: 0.9598\n",
            "Epoch 244/1000, Loss: 0.5032, Val Accuracy: 0.9598\n",
            "Epoch 245/1000, Loss: 0.5031, Val Accuracy: 0.9598\n",
            "Epoch 246/1000, Loss: 0.5031, Val Accuracy: 0.9598\n",
            "Epoch 247/1000, Loss: 0.5031, Val Accuracy: 0.9598\n",
            "Epoch 248/1000, Loss: 0.5031, Val Accuracy: 0.9598\n",
            "Epoch 249/1000, Loss: 0.5031, Val Accuracy: 0.9598\n",
            "Epoch 250/1000, Loss: 0.5031, Val Accuracy: 0.9571\n",
            "Epoch 251/1000, Loss: 0.5031, Val Accuracy: 0.9598\n",
            "Epoch 252/1000, Loss: 0.5031, Val Accuracy: 0.9598\n",
            "Epoch 253/1000, Loss: 0.5031, Val Accuracy: 0.9598\n",
            "Epoch 254/1000, Loss: 0.5030, Val Accuracy: 0.9571\n",
            "Epoch 255/1000, Loss: 0.5030, Val Accuracy: 0.9598\n",
            "Epoch 256/1000, Loss: 0.5030, Val Accuracy: 0.9571\n",
            "Epoch 257/1000, Loss: 0.5030, Val Accuracy: 0.9598\n",
            "Epoch 258/1000, Loss: 0.5030, Val Accuracy: 0.9598\n",
            "Epoch 259/1000, Loss: 0.5030, Val Accuracy: 0.9598\n",
            "Epoch 260/1000, Loss: 0.5030, Val Accuracy: 0.9598\n",
            "Epoch 261/1000, Loss: 0.5030, Val Accuracy: 0.9598\n",
            "Epoch 262/1000, Loss: 0.5030, Val Accuracy: 0.9598\n",
            "Epoch 263/1000, Loss: 0.5029, Val Accuracy: 0.9598\n",
            "Epoch 264/1000, Loss: 0.5029, Val Accuracy: 0.9598\n",
            "Epoch 265/1000, Loss: 0.5029, Val Accuracy: 0.9598\n",
            "Epoch 266/1000, Loss: 0.5029, Val Accuracy: 0.9571\n",
            "Epoch 267/1000, Loss: 0.5029, Val Accuracy: 0.9598\n",
            "Epoch 268/1000, Loss: 0.5029, Val Accuracy: 0.9598\n",
            "Epoch 269/1000, Loss: 0.5029, Val Accuracy: 0.9598\n",
            "Epoch 270/1000, Loss: 0.5029, Val Accuracy: 0.9598\n",
            "Epoch 271/1000, Loss: 0.5028, Val Accuracy: 0.9598\n",
            "Epoch 272/1000, Loss: 0.5028, Val Accuracy: 0.9598\n",
            "Epoch 273/1000, Loss: 0.5028, Val Accuracy: 0.9598\n",
            "Epoch 274/1000, Loss: 0.5028, Val Accuracy: 0.9598\n",
            "Epoch 275/1000, Loss: 0.5028, Val Accuracy: 0.9598\n",
            "Epoch 276/1000, Loss: 0.5028, Val Accuracy: 0.9598\n",
            "Epoch 277/1000, Loss: 0.5028, Val Accuracy: 0.9598\n",
            "Epoch 278/1000, Loss: 0.5028, Val Accuracy: 0.9598\n",
            "Epoch 279/1000, Loss: 0.5028, Val Accuracy: 0.9598\n",
            "Epoch 280/1000, Loss: 0.5028, Val Accuracy: 0.9598\n",
            "Epoch 281/1000, Loss: 0.5027, Val Accuracy: 0.9598\n",
            "Epoch 282/1000, Loss: 0.5027, Val Accuracy: 0.9598\n",
            "Epoch 283/1000, Loss: 0.5027, Val Accuracy: 0.9598\n",
            "Epoch 284/1000, Loss: 0.5027, Val Accuracy: 0.9598\n",
            "Epoch 285/1000, Loss: 0.5027, Val Accuracy: 0.9598\n",
            "Epoch 286/1000, Loss: 0.5027, Val Accuracy: 0.9598\n",
            "Epoch 287/1000, Loss: 0.5027, Val Accuracy: 0.9571\n",
            "Epoch 288/1000, Loss: 0.5027, Val Accuracy: 0.9598\n",
            "Epoch 289/1000, Loss: 0.5026, Val Accuracy: 0.9598\n",
            "Epoch 290/1000, Loss: 0.5026, Val Accuracy: 0.9598\n",
            "Epoch 291/1000, Loss: 0.5026, Val Accuracy: 0.9598\n",
            "Epoch 292/1000, Loss: 0.5026, Val Accuracy: 0.9598\n",
            "Epoch 293/1000, Loss: 0.5026, Val Accuracy: 0.9598\n",
            "Epoch 294/1000, Loss: 0.5026, Val Accuracy: 0.9598\n",
            "Epoch 295/1000, Loss: 0.5026, Val Accuracy: 0.9598\n",
            "Epoch 296/1000, Loss: 0.5026, Val Accuracy: 0.9625\n",
            "Epoch 297/1000, Loss: 0.5026, Val Accuracy: 0.9598\n",
            "Epoch 298/1000, Loss: 0.5025, Val Accuracy: 0.9598\n",
            "Epoch 299/1000, Loss: 0.5025, Val Accuracy: 0.9598\n",
            "Epoch 300/1000, Loss: 0.5025, Val Accuracy: 0.9571\n",
            "Epoch 301/1000, Loss: 0.5025, Val Accuracy: 0.9598\n",
            "Epoch 302/1000, Loss: 0.5025, Val Accuracy: 0.9598\n",
            "Epoch 303/1000, Loss: 0.5025, Val Accuracy: 0.9598\n",
            "Epoch 304/1000, Loss: 0.5025, Val Accuracy: 0.9598\n",
            "Epoch 305/1000, Loss: 0.5025, Val Accuracy: 0.9598\n",
            "Epoch 306/1000, Loss: 0.5025, Val Accuracy: 0.9625\n",
            "Epoch 307/1000, Loss: 0.5025, Val Accuracy: 0.9598\n",
            "Epoch 308/1000, Loss: 0.5024, Val Accuracy: 0.9598\n",
            "Epoch 309/1000, Loss: 0.5024, Val Accuracy: 0.9598\n",
            "Epoch 310/1000, Loss: 0.5024, Val Accuracy: 0.9598\n",
            "Epoch 311/1000, Loss: 0.5024, Val Accuracy: 0.9598\n",
            "Epoch 312/1000, Loss: 0.5024, Val Accuracy: 0.9598\n",
            "Epoch 313/1000, Loss: 0.5024, Val Accuracy: 0.9598\n",
            "Epoch 314/1000, Loss: 0.5024, Val Accuracy: 0.9598\n",
            "Epoch 315/1000, Loss: 0.5024, Val Accuracy: 0.9598\n",
            "Epoch 316/1000, Loss: 0.5024, Val Accuracy: 0.9598\n",
            "Epoch 317/1000, Loss: 0.5023, Val Accuracy: 0.9625\n",
            "Epoch 318/1000, Loss: 0.5023, Val Accuracy: 0.9598\n",
            "Epoch 319/1000, Loss: 0.5023, Val Accuracy: 0.9598\n",
            "Epoch 320/1000, Loss: 0.5023, Val Accuracy: 0.9598\n",
            "Epoch 321/1000, Loss: 0.5023, Val Accuracy: 0.9598\n",
            "Epoch 322/1000, Loss: 0.5023, Val Accuracy: 0.9598\n",
            "Epoch 323/1000, Loss: 0.5023, Val Accuracy: 0.9598\n",
            "Epoch 324/1000, Loss: 0.5023, Val Accuracy: 0.9598\n",
            "Epoch 325/1000, Loss: 0.5023, Val Accuracy: 0.9598\n",
            "Epoch 326/1000, Loss: 0.5023, Val Accuracy: 0.9598\n",
            "Epoch 327/1000, Loss: 0.5022, Val Accuracy: 0.9598\n",
            "Epoch 328/1000, Loss: 0.5022, Val Accuracy: 0.9598\n",
            "Epoch 329/1000, Loss: 0.5022, Val Accuracy: 0.9598\n",
            "Epoch 330/1000, Loss: 0.5022, Val Accuracy: 0.9598\n",
            "Epoch 331/1000, Loss: 0.5022, Val Accuracy: 0.9598\n",
            "Epoch 332/1000, Loss: 0.5022, Val Accuracy: 0.9598\n",
            "Epoch 333/1000, Loss: 0.5022, Val Accuracy: 0.9625\n",
            "Epoch 334/1000, Loss: 0.5022, Val Accuracy: 0.9598\n",
            "Epoch 335/1000, Loss: 0.5021, Val Accuracy: 0.9598\n",
            "Epoch 336/1000, Loss: 0.5021, Val Accuracy: 0.9625\n",
            "Epoch 337/1000, Loss: 0.5021, Val Accuracy: 0.9598\n",
            "Epoch 338/1000, Loss: 0.5021, Val Accuracy: 0.9625\n",
            "Epoch 339/1000, Loss: 0.5021, Val Accuracy: 0.9598\n",
            "Epoch 340/1000, Loss: 0.5021, Val Accuracy: 0.9598\n",
            "Epoch 341/1000, Loss: 0.5021, Val Accuracy: 0.9598\n",
            "Epoch 342/1000, Loss: 0.5021, Val Accuracy: 0.9598\n",
            "Epoch 343/1000, Loss: 0.5021, Val Accuracy: 0.9598\n",
            "Epoch 344/1000, Loss: 0.5021, Val Accuracy: 0.9598\n",
            "Epoch 345/1000, Loss: 0.5020, Val Accuracy: 0.9598\n",
            "Epoch 346/1000, Loss: 0.5020, Val Accuracy: 0.9598\n",
            "Epoch 347/1000, Loss: 0.5020, Val Accuracy: 0.9598\n",
            "Epoch 348/1000, Loss: 0.5020, Val Accuracy: 0.9625\n",
            "Epoch 349/1000, Loss: 0.5020, Val Accuracy: 0.9598\n",
            "Epoch 350/1000, Loss: 0.5020, Val Accuracy: 0.9598\n",
            "Epoch 351/1000, Loss: 0.5020, Val Accuracy: 0.9625\n",
            "Epoch 352/1000, Loss: 0.5020, Val Accuracy: 0.9598\n",
            "Epoch 353/1000, Loss: 0.5020, Val Accuracy: 0.9625\n",
            "Epoch 354/1000, Loss: 0.5019, Val Accuracy: 0.9598\n",
            "Epoch 355/1000, Loss: 0.5019, Val Accuracy: 0.9598\n",
            "Epoch 356/1000, Loss: 0.5019, Val Accuracy: 0.9598\n",
            "Epoch 357/1000, Loss: 0.5019, Val Accuracy: 0.9598\n",
            "Epoch 358/1000, Loss: 0.5019, Val Accuracy: 0.9598\n",
            "Epoch 359/1000, Loss: 0.5019, Val Accuracy: 0.9598\n",
            "Epoch 360/1000, Loss: 0.5019, Val Accuracy: 0.9598\n",
            "Epoch 361/1000, Loss: 0.5019, Val Accuracy: 0.9598\n",
            "Epoch 362/1000, Loss: 0.5019, Val Accuracy: 0.9598\n",
            "Epoch 363/1000, Loss: 0.5018, Val Accuracy: 0.9625\n",
            "Epoch 364/1000, Loss: 0.5018, Val Accuracy: 0.9598\n",
            "Epoch 365/1000, Loss: 0.5018, Val Accuracy: 0.9625\n",
            "Epoch 366/1000, Loss: 0.5018, Val Accuracy: 0.9625\n",
            "Epoch 367/1000, Loss: 0.5018, Val Accuracy: 0.9598\n",
            "Epoch 368/1000, Loss: 0.5018, Val Accuracy: 0.9625\n",
            "Epoch 369/1000, Loss: 0.5018, Val Accuracy: 0.9598\n",
            "Epoch 370/1000, Loss: 0.5018, Val Accuracy: 0.9625\n",
            "Epoch 371/1000, Loss: 0.5017, Val Accuracy: 0.9598\n",
            "Epoch 372/1000, Loss: 0.5017, Val Accuracy: 0.9625\n",
            "Epoch 373/1000, Loss: 0.5017, Val Accuracy: 0.9598\n",
            "Epoch 374/1000, Loss: 0.5017, Val Accuracy: 0.9625\n",
            "Epoch 375/1000, Loss: 0.5017, Val Accuracy: 0.9598\n",
            "Epoch 376/1000, Loss: 0.5017, Val Accuracy: 0.9625\n",
            "Epoch 377/1000, Loss: 0.5017, Val Accuracy: 0.9598\n",
            "Epoch 378/1000, Loss: 0.5016, Val Accuracy: 0.9625\n",
            "Epoch 379/1000, Loss: 0.5016, Val Accuracy: 0.9625\n",
            "Epoch 380/1000, Loss: 0.5016, Val Accuracy: 0.9625\n",
            "Epoch 381/1000, Loss: 0.5016, Val Accuracy: 0.9625\n",
            "Epoch 382/1000, Loss: 0.5016, Val Accuracy: 0.9625\n",
            "Epoch 383/1000, Loss: 0.5016, Val Accuracy: 0.9625\n",
            "Epoch 384/1000, Loss: 0.5016, Val Accuracy: 0.9625\n",
            "Epoch 385/1000, Loss: 0.5016, Val Accuracy: 0.9625\n",
            "Epoch 386/1000, Loss: 0.5016, Val Accuracy: 0.9625\n",
            "Epoch 387/1000, Loss: 0.5015, Val Accuracy: 0.9625\n",
            "Epoch 388/1000, Loss: 0.5015, Val Accuracy: 0.9625\n",
            "Epoch 389/1000, Loss: 0.5015, Val Accuracy: 0.9625\n",
            "Epoch 390/1000, Loss: 0.5015, Val Accuracy: 0.9625\n",
            "Epoch 391/1000, Loss: 0.5015, Val Accuracy: 0.9625\n",
            "Epoch 392/1000, Loss: 0.5015, Val Accuracy: 0.9625\n",
            "Epoch 393/1000, Loss: 0.5015, Val Accuracy: 0.9625\n",
            "Epoch 394/1000, Loss: 0.5015, Val Accuracy: 0.9625\n",
            "Epoch 395/1000, Loss: 0.5015, Val Accuracy: 0.9625\n",
            "Epoch 396/1000, Loss: 0.5014, Val Accuracy: 0.9625\n",
            "Epoch 397/1000, Loss: 0.5014, Val Accuracy: 0.9625\n",
            "Epoch 398/1000, Loss: 0.5014, Val Accuracy: 0.9625\n",
            "Epoch 399/1000, Loss: 0.5014, Val Accuracy: 0.9625\n",
            "Epoch 400/1000, Loss: 0.5014, Val Accuracy: 0.9625\n",
            "Epoch 401/1000, Loss: 0.5014, Val Accuracy: 0.9625\n",
            "Epoch 402/1000, Loss: 0.5014, Val Accuracy: 0.9625\n",
            "Epoch 403/1000, Loss: 0.5014, Val Accuracy: 0.9625\n",
            "Epoch 404/1000, Loss: 0.5014, Val Accuracy: 0.9625\n",
            "Epoch 405/1000, Loss: 0.5013, Val Accuracy: 0.9625\n",
            "Epoch 406/1000, Loss: 0.5013, Val Accuracy: 0.9625\n",
            "Epoch 407/1000, Loss: 0.5013, Val Accuracy: 0.9625\n",
            "Epoch 408/1000, Loss: 0.5013, Val Accuracy: 0.9625\n",
            "Epoch 409/1000, Loss: 0.5013, Val Accuracy: 0.9625\n",
            "Epoch 410/1000, Loss: 0.5013, Val Accuracy: 0.9598\n",
            "Epoch 411/1000, Loss: 0.5013, Val Accuracy: 0.9625\n",
            "Epoch 412/1000, Loss: 0.5013, Val Accuracy: 0.9598\n",
            "Epoch 413/1000, Loss: 0.5013, Val Accuracy: 0.9625\n",
            "Epoch 414/1000, Loss: 0.5013, Val Accuracy: 0.9598\n",
            "Epoch 415/1000, Loss: 0.5013, Val Accuracy: 0.9625\n",
            "Epoch 416/1000, Loss: 0.5012, Val Accuracy: 0.9598\n",
            "Epoch 417/1000, Loss: 0.5012, Val Accuracy: 0.9625\n",
            "Epoch 418/1000, Loss: 0.5012, Val Accuracy: 0.9598\n",
            "Epoch 419/1000, Loss: 0.5012, Val Accuracy: 0.9625\n",
            "Epoch 420/1000, Loss: 0.5012, Val Accuracy: 0.9625\n",
            "Epoch 421/1000, Loss: 0.5012, Val Accuracy: 0.9625\n",
            "Epoch 422/1000, Loss: 0.5012, Val Accuracy: 0.9625\n",
            "Epoch 423/1000, Loss: 0.5012, Val Accuracy: 0.9625\n",
            "Epoch 424/1000, Loss: 0.5012, Val Accuracy: 0.9625\n",
            "Epoch 425/1000, Loss: 0.5011, Val Accuracy: 0.9598\n",
            "Epoch 426/1000, Loss: 0.5011, Val Accuracy: 0.9625\n",
            "Epoch 427/1000, Loss: 0.5011, Val Accuracy: 0.9598\n",
            "Epoch 428/1000, Loss: 0.5011, Val Accuracy: 0.9625\n",
            "Epoch 429/1000, Loss: 0.5011, Val Accuracy: 0.9625\n",
            "Epoch 430/1000, Loss: 0.5011, Val Accuracy: 0.9625\n",
            "Epoch 431/1000, Loss: 0.5011, Val Accuracy: 0.9625\n",
            "Epoch 432/1000, Loss: 0.5011, Val Accuracy: 0.9625\n",
            "Epoch 433/1000, Loss: 0.5011, Val Accuracy: 0.9625\n",
            "Epoch 434/1000, Loss: 0.5011, Val Accuracy: 0.9625\n",
            "Epoch 435/1000, Loss: 0.5010, Val Accuracy: 0.9625\n",
            "Epoch 436/1000, Loss: 0.5010, Val Accuracy: 0.9625\n",
            "Epoch 437/1000, Loss: 0.5010, Val Accuracy: 0.9625\n",
            "Epoch 438/1000, Loss: 0.5010, Val Accuracy: 0.9625\n",
            "Epoch 439/1000, Loss: 0.5010, Val Accuracy: 0.9625\n",
            "Epoch 440/1000, Loss: 0.5010, Val Accuracy: 0.9625\n",
            "Epoch 441/1000, Loss: 0.5010, Val Accuracy: 0.9625\n",
            "Epoch 442/1000, Loss: 0.5010, Val Accuracy: 0.9625\n",
            "Epoch 443/1000, Loss: 0.5010, Val Accuracy: 0.9625\n",
            "Epoch 444/1000, Loss: 0.5010, Val Accuracy: 0.9625\n",
            "Epoch 445/1000, Loss: 0.5009, Val Accuracy: 0.9625\n",
            "Epoch 446/1000, Loss: 0.5009, Val Accuracy: 0.9625\n",
            "Epoch 447/1000, Loss: 0.5009, Val Accuracy: 0.9625\n",
            "Epoch 448/1000, Loss: 0.5009, Val Accuracy: 0.9625\n",
            "Epoch 449/1000, Loss: 0.5009, Val Accuracy: 0.9625\n",
            "Epoch 450/1000, Loss: 0.5009, Val Accuracy: 0.9625\n",
            "Epoch 451/1000, Loss: 0.5009, Val Accuracy: 0.9625\n",
            "Epoch 452/1000, Loss: 0.5009, Val Accuracy: 0.9625\n",
            "Epoch 453/1000, Loss: 0.5009, Val Accuracy: 0.9625\n",
            "Epoch 454/1000, Loss: 0.5009, Val Accuracy: 0.9625\n",
            "Epoch 455/1000, Loss: 0.5008, Val Accuracy: 0.9625\n",
            "Epoch 456/1000, Loss: 0.5008, Val Accuracy: 0.9625\n",
            "Epoch 457/1000, Loss: 0.5008, Val Accuracy: 0.9625\n",
            "Epoch 458/1000, Loss: 0.5008, Val Accuracy: 0.9625\n",
            "Epoch 459/1000, Loss: 0.5008, Val Accuracy: 0.9625\n",
            "Epoch 460/1000, Loss: 0.5008, Val Accuracy: 0.9625\n",
            "Epoch 461/1000, Loss: 0.5008, Val Accuracy: 0.9625\n",
            "Epoch 462/1000, Loss: 0.5008, Val Accuracy: 0.9625\n",
            "Epoch 463/1000, Loss: 0.5008, Val Accuracy: 0.9625\n",
            "Epoch 464/1000, Loss: 0.5008, Val Accuracy: 0.9625\n",
            "Epoch 465/1000, Loss: 0.5007, Val Accuracy: 0.9625\n",
            "Epoch 466/1000, Loss: 0.5007, Val Accuracy: 0.9625\n",
            "Epoch 467/1000, Loss: 0.5007, Val Accuracy: 0.9625\n",
            "Epoch 468/1000, Loss: 0.5007, Val Accuracy: 0.9625\n",
            "Epoch 469/1000, Loss: 0.5007, Val Accuracy: 0.9625\n",
            "Epoch 470/1000, Loss: 0.5007, Val Accuracy: 0.9625\n",
            "Epoch 471/1000, Loss: 0.5007, Val Accuracy: 0.9625\n",
            "Epoch 472/1000, Loss: 0.5007, Val Accuracy: 0.9625\n",
            "Epoch 473/1000, Loss: 0.5007, Val Accuracy: 0.9625\n",
            "Epoch 474/1000, Loss: 0.5007, Val Accuracy: 0.9625\n",
            "Epoch 475/1000, Loss: 0.5007, Val Accuracy: 0.9625\n",
            "Epoch 476/1000, Loss: 0.5006, Val Accuracy: 0.9625\n",
            "Epoch 477/1000, Loss: 0.5006, Val Accuracy: 0.9625\n",
            "Epoch 478/1000, Loss: 0.5006, Val Accuracy: 0.9625\n",
            "Epoch 479/1000, Loss: 0.5006, Val Accuracy: 0.9625\n",
            "Epoch 480/1000, Loss: 0.5006, Val Accuracy: 0.9625\n",
            "Epoch 481/1000, Loss: 0.5006, Val Accuracy: 0.9625\n",
            "Epoch 482/1000, Loss: 0.5006, Val Accuracy: 0.9625\n",
            "Epoch 483/1000, Loss: 0.5006, Val Accuracy: 0.9625\n",
            "Epoch 484/1000, Loss: 0.5006, Val Accuracy: 0.9625\n",
            "Epoch 485/1000, Loss: 0.5006, Val Accuracy: 0.9625\n",
            "Epoch 486/1000, Loss: 0.5005, Val Accuracy: 0.9625\n",
            "Epoch 487/1000, Loss: 0.5005, Val Accuracy: 0.9625\n",
            "Epoch 488/1000, Loss: 0.5005, Val Accuracy: 0.9625\n",
            "Epoch 489/1000, Loss: 0.5005, Val Accuracy: 0.9625\n",
            "Epoch 490/1000, Loss: 0.5005, Val Accuracy: 0.9625\n",
            "Epoch 491/1000, Loss: 0.5005, Val Accuracy: 0.9625\n",
            "Epoch 492/1000, Loss: 0.5005, Val Accuracy: 0.9625\n",
            "Epoch 493/1000, Loss: 0.5005, Val Accuracy: 0.9625\n",
            "Epoch 494/1000, Loss: 0.5005, Val Accuracy: 0.9625\n",
            "Epoch 495/1000, Loss: 0.5005, Val Accuracy: 0.9625\n",
            "Epoch 496/1000, Loss: 0.5004, Val Accuracy: 0.9625\n",
            "Epoch 497/1000, Loss: 0.5004, Val Accuracy: 0.9625\n",
            "Epoch 498/1000, Loss: 0.5004, Val Accuracy: 0.9625\n",
            "Epoch 499/1000, Loss: 0.5004, Val Accuracy: 0.9625\n",
            "Epoch 500/1000, Loss: 0.5004, Val Accuracy: 0.9625\n",
            "Epoch 501/1000, Loss: 0.5004, Val Accuracy: 0.9625\n",
            "Epoch 502/1000, Loss: 0.5004, Val Accuracy: 0.9625\n",
            "Epoch 503/1000, Loss: 0.5004, Val Accuracy: 0.9625\n",
            "Epoch 504/1000, Loss: 0.5004, Val Accuracy: 0.9625\n",
            "Epoch 505/1000, Loss: 0.5004, Val Accuracy: 0.9625\n",
            "Epoch 506/1000, Loss: 0.5004, Val Accuracy: 0.9625\n",
            "Epoch 507/1000, Loss: 0.5003, Val Accuracy: 0.9625\n",
            "Epoch 508/1000, Loss: 0.5003, Val Accuracy: 0.9625\n",
            "Epoch 509/1000, Loss: 0.5003, Val Accuracy: 0.9625\n",
            "Epoch 510/1000, Loss: 0.5003, Val Accuracy: 0.9625\n",
            "Epoch 511/1000, Loss: 0.5003, Val Accuracy: 0.9625\n",
            "Epoch 512/1000, Loss: 0.5003, Val Accuracy: 0.9625\n",
            "Epoch 513/1000, Loss: 0.5003, Val Accuracy: 0.9625\n",
            "Epoch 514/1000, Loss: 0.5003, Val Accuracy: 0.9625\n",
            "Epoch 515/1000, Loss: 0.5003, Val Accuracy: 0.9625\n",
            "Epoch 516/1000, Loss: 0.5003, Val Accuracy: 0.9625\n",
            "Epoch 517/1000, Loss: 0.5002, Val Accuracy: 0.9625\n",
            "Epoch 518/1000, Loss: 0.5002, Val Accuracy: 0.9625\n",
            "Epoch 519/1000, Loss: 0.5002, Val Accuracy: 0.9625\n",
            "Epoch 520/1000, Loss: 0.5002, Val Accuracy: 0.9625\n",
            "Epoch 521/1000, Loss: 0.5002, Val Accuracy: 0.9625\n",
            "Epoch 522/1000, Loss: 0.5002, Val Accuracy: 0.9625\n",
            "Epoch 523/1000, Loss: 0.5002, Val Accuracy: 0.9625\n",
            "Epoch 524/1000, Loss: 0.5002, Val Accuracy: 0.9625\n",
            "Epoch 525/1000, Loss: 0.5002, Val Accuracy: 0.9625\n",
            "Epoch 526/1000, Loss: 0.5002, Val Accuracy: 0.9625\n",
            "Epoch 527/1000, Loss: 0.5002, Val Accuracy: 0.9625\n",
            "Epoch 528/1000, Loss: 0.5001, Val Accuracy: 0.9625\n",
            "Epoch 529/1000, Loss: 0.5001, Val Accuracy: 0.9625\n",
            "Epoch 530/1000, Loss: 0.5001, Val Accuracy: 0.9625\n",
            "Epoch 531/1000, Loss: 0.5001, Val Accuracy: 0.9625\n",
            "Epoch 532/1000, Loss: 0.5001, Val Accuracy: 0.9625\n",
            "Epoch 533/1000, Loss: 0.5001, Val Accuracy: 0.9625\n",
            "Epoch 534/1000, Loss: 0.5001, Val Accuracy: 0.9625\n",
            "Epoch 535/1000, Loss: 0.5001, Val Accuracy: 0.9625\n",
            "Epoch 536/1000, Loss: 0.5001, Val Accuracy: 0.9625\n",
            "Epoch 537/1000, Loss: 0.5001, Val Accuracy: 0.9625\n",
            "Epoch 538/1000, Loss: 0.5000, Val Accuracy: 0.9625\n",
            "Epoch 539/1000, Loss: 0.5000, Val Accuracy: 0.9625\n",
            "Epoch 540/1000, Loss: 0.5000, Val Accuracy: 0.9625\n",
            "Epoch 541/1000, Loss: 0.5000, Val Accuracy: 0.9625\n",
            "Epoch 542/1000, Loss: 0.5000, Val Accuracy: 0.9625\n",
            "Epoch 543/1000, Loss: 0.5000, Val Accuracy: 0.9625\n",
            "Epoch 544/1000, Loss: 0.5000, Val Accuracy: 0.9625\n",
            "Epoch 545/1000, Loss: 0.5000, Val Accuracy: 0.9625\n",
            "Epoch 546/1000, Loss: 0.5000, Val Accuracy: 0.9625\n",
            "Epoch 547/1000, Loss: 0.5000, Val Accuracy: 0.9625\n",
            "Epoch 548/1000, Loss: 0.5000, Val Accuracy: 0.9625\n",
            "Epoch 549/1000, Loss: 0.4999, Val Accuracy: 0.9625\n",
            "Epoch 550/1000, Loss: 0.4999, Val Accuracy: 0.9625\n",
            "Epoch 551/1000, Loss: 0.4999, Val Accuracy: 0.9625\n",
            "Epoch 552/1000, Loss: 0.4999, Val Accuracy: 0.9625\n",
            "Epoch 553/1000, Loss: 0.4999, Val Accuracy: 0.9625\n",
            "Epoch 554/1000, Loss: 0.4999, Val Accuracy: 0.9625\n",
            "Epoch 555/1000, Loss: 0.4999, Val Accuracy: 0.9625\n",
            "Epoch 556/1000, Loss: 0.4999, Val Accuracy: 0.9625\n",
            "Epoch 557/1000, Loss: 0.4999, Val Accuracy: 0.9625\n",
            "Epoch 558/1000, Loss: 0.4999, Val Accuracy: 0.9625\n",
            "Epoch 559/1000, Loss: 0.4999, Val Accuracy: 0.9625\n",
            "Epoch 560/1000, Loss: 0.4998, Val Accuracy: 0.9625\n",
            "Epoch 561/1000, Loss: 0.4998, Val Accuracy: 0.9625\n",
            "Epoch 562/1000, Loss: 0.4998, Val Accuracy: 0.9598\n",
            "Epoch 563/1000, Loss: 0.4998, Val Accuracy: 0.9625\n",
            "Epoch 564/1000, Loss: 0.4998, Val Accuracy: 0.9598\n",
            "Epoch 565/1000, Loss: 0.4998, Val Accuracy: 0.9625\n",
            "Epoch 566/1000, Loss: 0.4998, Val Accuracy: 0.9598\n",
            "Epoch 567/1000, Loss: 0.4998, Val Accuracy: 0.9625\n",
            "Epoch 568/1000, Loss: 0.4998, Val Accuracy: 0.9625\n",
            "Epoch 569/1000, Loss: 0.4998, Val Accuracy: 0.9625\n",
            "Epoch 570/1000, Loss: 0.4997, Val Accuracy: 0.9625\n",
            "Epoch 571/1000, Loss: 0.4997, Val Accuracy: 0.9625\n",
            "Epoch 572/1000, Loss: 0.4997, Val Accuracy: 0.9625\n",
            "Epoch 573/1000, Loss: 0.4997, Val Accuracy: 0.9625\n",
            "Epoch 574/1000, Loss: 0.4997, Val Accuracy: 0.9625\n",
            "Epoch 575/1000, Loss: 0.4997, Val Accuracy: 0.9625\n",
            "Epoch 576/1000, Loss: 0.4997, Val Accuracy: 0.9625\n",
            "Epoch 577/1000, Loss: 0.4997, Val Accuracy: 0.9625\n",
            "Epoch 578/1000, Loss: 0.4997, Val Accuracy: 0.9625\n",
            "Epoch 579/1000, Loss: 0.4997, Val Accuracy: 0.9625\n",
            "Epoch 580/1000, Loss: 0.4997, Val Accuracy: 0.9625\n",
            "Epoch 581/1000, Loss: 0.4996, Val Accuracy: 0.9625\n",
            "Epoch 582/1000, Loss: 0.4996, Val Accuracy: 0.9625\n",
            "Epoch 583/1000, Loss: 0.4996, Val Accuracy: 0.9625\n",
            "Epoch 584/1000, Loss: 0.4996, Val Accuracy: 0.9625\n",
            "Epoch 585/1000, Loss: 0.4996, Val Accuracy: 0.9625\n",
            "Epoch 586/1000, Loss: 0.4996, Val Accuracy: 0.9625\n",
            "Epoch 587/1000, Loss: 0.4996, Val Accuracy: 0.9625\n",
            "Epoch 588/1000, Loss: 0.4996, Val Accuracy: 0.9625\n",
            "Epoch 589/1000, Loss: 0.4996, Val Accuracy: 0.9625\n",
            "Epoch 590/1000, Loss: 0.4996, Val Accuracy: 0.9625\n",
            "Epoch 591/1000, Loss: 0.4996, Val Accuracy: 0.9625\n",
            "Epoch 592/1000, Loss: 0.4995, Val Accuracy: 0.9625\n",
            "Epoch 593/1000, Loss: 0.4995, Val Accuracy: 0.9625\n",
            "Epoch 594/1000, Loss: 0.4995, Val Accuracy: 0.9625\n",
            "Epoch 595/1000, Loss: 0.4995, Val Accuracy: 0.9625\n",
            "Epoch 596/1000, Loss: 0.4995, Val Accuracy: 0.9625\n",
            "Epoch 597/1000, Loss: 0.4995, Val Accuracy: 0.9625\n",
            "Epoch 598/1000, Loss: 0.4995, Val Accuracy: 0.9625\n",
            "Epoch 599/1000, Loss: 0.4995, Val Accuracy: 0.9625\n",
            "Epoch 600/1000, Loss: 0.4995, Val Accuracy: 0.9625\n",
            "Epoch 601/1000, Loss: 0.4995, Val Accuracy: 0.9625\n",
            "Epoch 602/1000, Loss: 0.4994, Val Accuracy: 0.9625\n",
            "Epoch 603/1000, Loss: 0.4994, Val Accuracy: 0.9625\n",
            "Epoch 604/1000, Loss: 0.4994, Val Accuracy: 0.9625\n",
            "Epoch 605/1000, Loss: 0.4994, Val Accuracy: 0.9625\n",
            "Epoch 606/1000, Loss: 0.4994, Val Accuracy: 0.9625\n",
            "Epoch 607/1000, Loss: 0.4994, Val Accuracy: 0.9625\n",
            "Epoch 608/1000, Loss: 0.4994, Val Accuracy: 0.9625\n",
            "Epoch 609/1000, Loss: 0.4994, Val Accuracy: 0.9625\n",
            "Epoch 610/1000, Loss: 0.4994, Val Accuracy: 0.9625\n",
            "Epoch 611/1000, Loss: 0.4994, Val Accuracy: 0.9598\n",
            "Epoch 612/1000, Loss: 0.4993, Val Accuracy: 0.9625\n",
            "Epoch 613/1000, Loss: 0.4993, Val Accuracy: 0.9598\n",
            "Epoch 614/1000, Loss: 0.4993, Val Accuracy: 0.9598\n",
            "Epoch 615/1000, Loss: 0.4993, Val Accuracy: 0.9598\n",
            "Epoch 616/1000, Loss: 0.4993, Val Accuracy: 0.9598\n",
            "Epoch 617/1000, Loss: 0.4993, Val Accuracy: 0.9598\n",
            "Epoch 618/1000, Loss: 0.4993, Val Accuracy: 0.9598\n",
            "Epoch 619/1000, Loss: 0.4993, Val Accuracy: 0.9598\n",
            "Epoch 620/1000, Loss: 0.4993, Val Accuracy: 0.9598\n",
            "Epoch 621/1000, Loss: 0.4993, Val Accuracy: 0.9598\n",
            "Epoch 622/1000, Loss: 0.4993, Val Accuracy: 0.9598\n",
            "Epoch 623/1000, Loss: 0.4992, Val Accuracy: 0.9598\n",
            "Epoch 624/1000, Loss: 0.4992, Val Accuracy: 0.9598\n",
            "Epoch 625/1000, Loss: 0.4992, Val Accuracy: 0.9598\n",
            "Epoch 626/1000, Loss: 0.4992, Val Accuracy: 0.9598\n",
            "Epoch 627/1000, Loss: 0.4992, Val Accuracy: 0.9598\n",
            "Epoch 628/1000, Loss: 0.4992, Val Accuracy: 0.9598\n",
            "Epoch 629/1000, Loss: 0.4992, Val Accuracy: 0.9598\n",
            "Epoch 630/1000, Loss: 0.4992, Val Accuracy: 0.9625\n",
            "Epoch 631/1000, Loss: 0.4992, Val Accuracy: 0.9598\n",
            "Epoch 632/1000, Loss: 0.4992, Val Accuracy: 0.9598\n",
            "Epoch 633/1000, Loss: 0.4992, Val Accuracy: 0.9598\n",
            "Epoch 634/1000, Loss: 0.4992, Val Accuracy: 0.9598\n",
            "Epoch 635/1000, Loss: 0.4991, Val Accuracy: 0.9598\n",
            "Epoch 636/1000, Loss: 0.4991, Val Accuracy: 0.9598\n",
            "Epoch 637/1000, Loss: 0.4991, Val Accuracy: 0.9598\n",
            "Epoch 638/1000, Loss: 0.4991, Val Accuracy: 0.9598\n",
            "Epoch 639/1000, Loss: 0.4991, Val Accuracy: 0.9598\n",
            "Epoch 640/1000, Loss: 0.4991, Val Accuracy: 0.9598\n",
            "Epoch 641/1000, Loss: 0.4991, Val Accuracy: 0.9598\n",
            "Epoch 642/1000, Loss: 0.4991, Val Accuracy: 0.9598\n",
            "Epoch 643/1000, Loss: 0.4991, Val Accuracy: 0.9598\n",
            "Epoch 644/1000, Loss: 0.4991, Val Accuracy: 0.9598\n",
            "Epoch 645/1000, Loss: 0.4991, Val Accuracy: 0.9598\n",
            "Epoch 646/1000, Loss: 0.4991, Val Accuracy: 0.9598\n",
            "Epoch 647/1000, Loss: 0.4990, Val Accuracy: 0.9625\n",
            "Epoch 648/1000, Loss: 0.4990, Val Accuracy: 0.9598\n",
            "Epoch 649/1000, Loss: 0.4990, Val Accuracy: 0.9625\n",
            "Epoch 650/1000, Loss: 0.4990, Val Accuracy: 0.9598\n",
            "Epoch 651/1000, Loss: 0.4990, Val Accuracy: 0.9598\n",
            "Epoch 652/1000, Loss: 0.4990, Val Accuracy: 0.9598\n",
            "Epoch 653/1000, Loss: 0.4990, Val Accuracy: 0.9598\n",
            "Epoch 654/1000, Loss: 0.4990, Val Accuracy: 0.9598\n",
            "Epoch 655/1000, Loss: 0.4990, Val Accuracy: 0.9598\n",
            "Epoch 656/1000, Loss: 0.4990, Val Accuracy: 0.9598\n",
            "Epoch 657/1000, Loss: 0.4990, Val Accuracy: 0.9598\n",
            "Epoch 658/1000, Loss: 0.4989, Val Accuracy: 0.9598\n",
            "Epoch 659/1000, Loss: 0.4989, Val Accuracy: 0.9598\n",
            "Epoch 660/1000, Loss: 0.4989, Val Accuracy: 0.9598\n",
            "Epoch 661/1000, Loss: 0.4989, Val Accuracy: 0.9598\n",
            "Epoch 662/1000, Loss: 0.4989, Val Accuracy: 0.9598\n",
            "Epoch 663/1000, Loss: 0.4989, Val Accuracy: 0.9598\n",
            "Epoch 664/1000, Loss: 0.4989, Val Accuracy: 0.9598\n",
            "Epoch 665/1000, Loss: 0.4989, Val Accuracy: 0.9598\n",
            "Epoch 666/1000, Loss: 0.4989, Val Accuracy: 0.9625\n",
            "Epoch 667/1000, Loss: 0.4989, Val Accuracy: 0.9598\n",
            "Epoch 668/1000, Loss: 0.4989, Val Accuracy: 0.9625\n",
            "Epoch 669/1000, Loss: 0.4989, Val Accuracy: 0.9598\n",
            "Epoch 670/1000, Loss: 0.4989, Val Accuracy: 0.9625\n",
            "Epoch 671/1000, Loss: 0.4988, Val Accuracy: 0.9598\n",
            "Epoch 672/1000, Loss: 0.4988, Val Accuracy: 0.9598\n",
            "Epoch 673/1000, Loss: 0.4988, Val Accuracy: 0.9598\n",
            "Epoch 674/1000, Loss: 0.4988, Val Accuracy: 0.9598\n",
            "Epoch 675/1000, Loss: 0.4988, Val Accuracy: 0.9598\n",
            "Epoch 676/1000, Loss: 0.4988, Val Accuracy: 0.9598\n",
            "Epoch 677/1000, Loss: 0.4988, Val Accuracy: 0.9598\n",
            "Epoch 678/1000, Loss: 0.4988, Val Accuracy: 0.9598\n",
            "Epoch 679/1000, Loss: 0.4988, Val Accuracy: 0.9598\n",
            "Epoch 680/1000, Loss: 0.4988, Val Accuracy: 0.9598\n",
            "Epoch 681/1000, Loss: 0.4988, Val Accuracy: 0.9598\n",
            "Epoch 682/1000, Loss: 0.4987, Val Accuracy: 0.9598\n",
            "Epoch 683/1000, Loss: 0.4987, Val Accuracy: 0.9598\n",
            "Epoch 684/1000, Loss: 0.4987, Val Accuracy: 0.9598\n",
            "Epoch 685/1000, Loss: 0.4987, Val Accuracy: 0.9598\n",
            "Epoch 686/1000, Loss: 0.4987, Val Accuracy: 0.9598\n",
            "Epoch 687/1000, Loss: 0.4987, Val Accuracy: 0.9598\n",
            "Epoch 688/1000, Loss: 0.4987, Val Accuracy: 0.9598\n",
            "Epoch 689/1000, Loss: 0.4987, Val Accuracy: 0.9598\n",
            "Epoch 690/1000, Loss: 0.4987, Val Accuracy: 0.9598\n",
            "Epoch 691/1000, Loss: 0.4987, Val Accuracy: 0.9598\n",
            "Epoch 692/1000, Loss: 0.4987, Val Accuracy: 0.9598\n",
            "Epoch 693/1000, Loss: 0.4987, Val Accuracy: 0.9598\n",
            "Epoch 694/1000, Loss: 0.4986, Val Accuracy: 0.9598\n",
            "Epoch 695/1000, Loss: 0.4986, Val Accuracy: 0.9598\n",
            "Epoch 696/1000, Loss: 0.4986, Val Accuracy: 0.9598\n",
            "Epoch 697/1000, Loss: 0.4986, Val Accuracy: 0.9598\n",
            "Epoch 698/1000, Loss: 0.4986, Val Accuracy: 0.9598\n",
            "Epoch 699/1000, Loss: 0.4986, Val Accuracy: 0.9598\n",
            "Epoch 700/1000, Loss: 0.4986, Val Accuracy: 0.9598\n",
            "Epoch 701/1000, Loss: 0.4986, Val Accuracy: 0.9598\n",
            "Epoch 702/1000, Loss: 0.4986, Val Accuracy: 0.9598\n",
            "Epoch 703/1000, Loss: 0.4986, Val Accuracy: 0.9598\n",
            "Epoch 704/1000, Loss: 0.4986, Val Accuracy: 0.9598\n",
            "Epoch 705/1000, Loss: 0.4986, Val Accuracy: 0.9598\n",
            "Epoch 706/1000, Loss: 0.4985, Val Accuracy: 0.9598\n",
            "Epoch 707/1000, Loss: 0.4985, Val Accuracy: 0.9598\n",
            "Epoch 708/1000, Loss: 0.4985, Val Accuracy: 0.9625\n",
            "Epoch 709/1000, Loss: 0.4985, Val Accuracy: 0.9598\n",
            "Epoch 710/1000, Loss: 0.4985, Val Accuracy: 0.9598\n",
            "Epoch 711/1000, Loss: 0.4985, Val Accuracy: 0.9598\n",
            "Epoch 712/1000, Loss: 0.4985, Val Accuracy: 0.9598\n",
            "Epoch 713/1000, Loss: 0.4985, Val Accuracy: 0.9598\n",
            "Epoch 714/1000, Loss: 0.4985, Val Accuracy: 0.9598\n",
            "Epoch 715/1000, Loss: 0.4985, Val Accuracy: 0.9598\n",
            "Epoch 716/1000, Loss: 0.4985, Val Accuracy: 0.9598\n",
            "Epoch 717/1000, Loss: 0.4985, Val Accuracy: 0.9598\n",
            "Epoch 718/1000, Loss: 0.4984, Val Accuracy: 0.9598\n",
            "Epoch 719/1000, Loss: 0.4984, Val Accuracy: 0.9598\n",
            "Epoch 720/1000, Loss: 0.4984, Val Accuracy: 0.9598\n",
            "Epoch 721/1000, Loss: 0.4984, Val Accuracy: 0.9598\n",
            "Epoch 722/1000, Loss: 0.4984, Val Accuracy: 0.9598\n",
            "Epoch 723/1000, Loss: 0.4984, Val Accuracy: 0.9598\n",
            "Epoch 724/1000, Loss: 0.4984, Val Accuracy: 0.9598\n",
            "Epoch 725/1000, Loss: 0.4984, Val Accuracy: 0.9598\n",
            "Epoch 726/1000, Loss: 0.4984, Val Accuracy: 0.9598\n",
            "Epoch 727/1000, Loss: 0.4984, Val Accuracy: 0.9598\n",
            "Epoch 728/1000, Loss: 0.4984, Val Accuracy: 0.9598\n",
            "Epoch 729/1000, Loss: 0.4984, Val Accuracy: 0.9598\n",
            "Epoch 730/1000, Loss: 0.4984, Val Accuracy: 0.9598\n",
            "Epoch 731/1000, Loss: 0.4983, Val Accuracy: 0.9598\n",
            "Epoch 732/1000, Loss: 0.4983, Val Accuracy: 0.9598\n",
            "Epoch 733/1000, Loss: 0.4983, Val Accuracy: 0.9598\n",
            "Epoch 734/1000, Loss: 0.4983, Val Accuracy: 0.9598\n",
            "Epoch 735/1000, Loss: 0.4983, Val Accuracy: 0.9598\n",
            "Epoch 736/1000, Loss: 0.4983, Val Accuracy: 0.9598\n",
            "Epoch 737/1000, Loss: 0.4983, Val Accuracy: 0.9598\n",
            "Epoch 738/1000, Loss: 0.4983, Val Accuracy: 0.9598\n",
            "Epoch 739/1000, Loss: 0.4983, Val Accuracy: 0.9598\n",
            "Epoch 740/1000, Loss: 0.4983, Val Accuracy: 0.9598\n",
            "Epoch 741/1000, Loss: 0.4983, Val Accuracy: 0.9598\n",
            "Epoch 742/1000, Loss: 0.4983, Val Accuracy: 0.9598\n",
            "Epoch 743/1000, Loss: 0.4983, Val Accuracy: 0.9598\n",
            "Epoch 744/1000, Loss: 0.4982, Val Accuracy: 0.9625\n",
            "Epoch 745/1000, Loss: 0.4982, Val Accuracy: 0.9625\n",
            "Epoch 746/1000, Loss: 0.4982, Val Accuracy: 0.9625\n",
            "Epoch 747/1000, Loss: 0.4982, Val Accuracy: 0.9598\n",
            "Epoch 748/1000, Loss: 0.4982, Val Accuracy: 0.9598\n",
            "Epoch 749/1000, Loss: 0.4982, Val Accuracy: 0.9598\n",
            "Epoch 750/1000, Loss: 0.4982, Val Accuracy: 0.9598\n",
            "Epoch 751/1000, Loss: 0.4982, Val Accuracy: 0.9598\n",
            "Epoch 752/1000, Loss: 0.4982, Val Accuracy: 0.9598\n",
            "Epoch 753/1000, Loss: 0.4982, Val Accuracy: 0.9598\n",
            "Epoch 754/1000, Loss: 0.4982, Val Accuracy: 0.9598\n",
            "Epoch 755/1000, Loss: 0.4982, Val Accuracy: 0.9598\n",
            "Epoch 756/1000, Loss: 0.4981, Val Accuracy: 0.9625\n",
            "Epoch 757/1000, Loss: 0.4981, Val Accuracy: 0.9598\n",
            "Epoch 758/1000, Loss: 0.4981, Val Accuracy: 0.9598\n",
            "Epoch 759/1000, Loss: 0.4981, Val Accuracy: 0.9598\n",
            "Epoch 760/1000, Loss: 0.4981, Val Accuracy: 0.9598\n",
            "Epoch 761/1000, Loss: 0.4981, Val Accuracy: 0.9598\n",
            "Epoch 762/1000, Loss: 0.4981, Val Accuracy: 0.9598\n",
            "Epoch 763/1000, Loss: 0.4981, Val Accuracy: 0.9598\n",
            "Epoch 764/1000, Loss: 0.4981, Val Accuracy: 0.9598\n",
            "Epoch 765/1000, Loss: 0.4981, Val Accuracy: 0.9598\n",
            "Epoch 766/1000, Loss: 0.4981, Val Accuracy: 0.9598\n",
            "Epoch 767/1000, Loss: 0.4981, Val Accuracy: 0.9598\n",
            "Epoch 768/1000, Loss: 0.4980, Val Accuracy: 0.9598\n",
            "Epoch 769/1000, Loss: 0.4980, Val Accuracy: 0.9598\n",
            "Epoch 770/1000, Loss: 0.4980, Val Accuracy: 0.9598\n",
            "Epoch 771/1000, Loss: 0.4980, Val Accuracy: 0.9598\n",
            "Epoch 772/1000, Loss: 0.4980, Val Accuracy: 0.9598\n",
            "Epoch 773/1000, Loss: 0.4980, Val Accuracy: 0.9598\n",
            "Epoch 774/1000, Loss: 0.4980, Val Accuracy: 0.9598\n",
            "Epoch 775/1000, Loss: 0.4980, Val Accuracy: 0.9598\n",
            "Epoch 776/1000, Loss: 0.4980, Val Accuracy: 0.9598\n",
            "Epoch 777/1000, Loss: 0.4980, Val Accuracy: 0.9598\n",
            "Epoch 778/1000, Loss: 0.4980, Val Accuracy: 0.9598\n",
            "Epoch 779/1000, Loss: 0.4980, Val Accuracy: 0.9625\n",
            "Epoch 780/1000, Loss: 0.4980, Val Accuracy: 0.9598\n",
            "Epoch 781/1000, Loss: 0.4980, Val Accuracy: 0.9625\n",
            "Epoch 782/1000, Loss: 0.4979, Val Accuracy: 0.9625\n",
            "Epoch 783/1000, Loss: 0.4979, Val Accuracy: 0.9625\n",
            "Epoch 784/1000, Loss: 0.4979, Val Accuracy: 0.9625\n",
            "Epoch 785/1000, Loss: 0.4979, Val Accuracy: 0.9625\n",
            "Epoch 786/1000, Loss: 0.4979, Val Accuracy: 0.9625\n",
            "Epoch 787/1000, Loss: 0.4979, Val Accuracy: 0.9625\n",
            "Epoch 788/1000, Loss: 0.4979, Val Accuracy: 0.9625\n",
            "Epoch 789/1000, Loss: 0.4979, Val Accuracy: 0.9625\n",
            "Epoch 790/1000, Loss: 0.4979, Val Accuracy: 0.9625\n",
            "Epoch 791/1000, Loss: 0.4979, Val Accuracy: 0.9625\n",
            "Epoch 792/1000, Loss: 0.4979, Val Accuracy: 0.9598\n",
            "Epoch 793/1000, Loss: 0.4979, Val Accuracy: 0.9598\n",
            "Epoch 794/1000, Loss: 0.4978, Val Accuracy: 0.9598\n",
            "Epoch 795/1000, Loss: 0.4978, Val Accuracy: 0.9598\n",
            "Epoch 796/1000, Loss: 0.4978, Val Accuracy: 0.9598\n",
            "Epoch 797/1000, Loss: 0.4978, Val Accuracy: 0.9598\n",
            "Epoch 798/1000, Loss: 0.4978, Val Accuracy: 0.9598\n",
            "Epoch 799/1000, Loss: 0.4978, Val Accuracy: 0.9598\n",
            "Epoch 800/1000, Loss: 0.4978, Val Accuracy: 0.9598\n",
            "Epoch 801/1000, Loss: 0.4978, Val Accuracy: 0.9598\n",
            "Epoch 802/1000, Loss: 0.4978, Val Accuracy: 0.9598\n",
            "Epoch 803/1000, Loss: 0.4978, Val Accuracy: 0.9598\n",
            "Epoch 804/1000, Loss: 0.4978, Val Accuracy: 0.9625\n",
            "Epoch 805/1000, Loss: 0.4978, Val Accuracy: 0.9598\n",
            "Epoch 806/1000, Loss: 0.4978, Val Accuracy: 0.9625\n",
            "Epoch 807/1000, Loss: 0.4978, Val Accuracy: 0.9598\n",
            "Epoch 808/1000, Loss: 0.4977, Val Accuracy: 0.9625\n",
            "Epoch 809/1000, Loss: 0.4977, Val Accuracy: 0.9598\n",
            "Epoch 810/1000, Loss: 0.4977, Val Accuracy: 0.9625\n",
            "Epoch 811/1000, Loss: 0.4977, Val Accuracy: 0.9598\n",
            "Epoch 812/1000, Loss: 0.4977, Val Accuracy: 0.9625\n",
            "Epoch 813/1000, Loss: 0.4977, Val Accuracy: 0.9598\n",
            "Epoch 814/1000, Loss: 0.4977, Val Accuracy: 0.9625\n",
            "Epoch 815/1000, Loss: 0.4977, Val Accuracy: 0.9598\n",
            "Epoch 816/1000, Loss: 0.4977, Val Accuracy: 0.9598\n",
            "Epoch 817/1000, Loss: 0.4977, Val Accuracy: 0.9598\n",
            "Epoch 818/1000, Loss: 0.4977, Val Accuracy: 0.9598\n",
            "Epoch 819/1000, Loss: 0.4977, Val Accuracy: 0.9598\n",
            "Epoch 820/1000, Loss: 0.4976, Val Accuracy: 0.9598\n",
            "Epoch 821/1000, Loss: 0.4976, Val Accuracy: 0.9598\n",
            "Epoch 822/1000, Loss: 0.4976, Val Accuracy: 0.9598\n",
            "Epoch 823/1000, Loss: 0.4976, Val Accuracy: 0.9598\n",
            "Epoch 824/1000, Loss: 0.4976, Val Accuracy: 0.9598\n",
            "Epoch 825/1000, Loss: 0.4976, Val Accuracy: 0.9625\n",
            "Epoch 826/1000, Loss: 0.4976, Val Accuracy: 0.9598\n",
            "Epoch 827/1000, Loss: 0.4976, Val Accuracy: 0.9625\n",
            "Epoch 828/1000, Loss: 0.4976, Val Accuracy: 0.9598\n",
            "Epoch 829/1000, Loss: 0.4976, Val Accuracy: 0.9625\n",
            "Epoch 830/1000, Loss: 0.4976, Val Accuracy: 0.9598\n",
            "Epoch 831/1000, Loss: 0.4976, Val Accuracy: 0.9625\n",
            "Epoch 832/1000, Loss: 0.4976, Val Accuracy: 0.9598\n",
            "Epoch 833/1000, Loss: 0.4976, Val Accuracy: 0.9625\n",
            "Epoch 834/1000, Loss: 0.4975, Val Accuracy: 0.9598\n",
            "Epoch 835/1000, Loss: 0.4975, Val Accuracy: 0.9625\n",
            "Epoch 836/1000, Loss: 0.4975, Val Accuracy: 0.9598\n",
            "Epoch 837/1000, Loss: 0.4975, Val Accuracy: 0.9598\n",
            "Epoch 838/1000, Loss: 0.4975, Val Accuracy: 0.9598\n",
            "Epoch 839/1000, Loss: 0.4975, Val Accuracy: 0.9625\n",
            "Epoch 840/1000, Loss: 0.4975, Val Accuracy: 0.9598\n",
            "Epoch 841/1000, Loss: 0.4975, Val Accuracy: 0.9598\n",
            "Epoch 842/1000, Loss: 0.4975, Val Accuracy: 0.9598\n",
            "Epoch 843/1000, Loss: 0.4975, Val Accuracy: 0.9598\n",
            "Epoch 844/1000, Loss: 0.4975, Val Accuracy: 0.9598\n",
            "Epoch 845/1000, Loss: 0.4975, Val Accuracy: 0.9598\n",
            "Epoch 846/1000, Loss: 0.4974, Val Accuracy: 0.9598\n",
            "Epoch 847/1000, Loss: 0.4974, Val Accuracy: 0.9598\n",
            "Epoch 848/1000, Loss: 0.4974, Val Accuracy: 0.9625\n",
            "Epoch 849/1000, Loss: 0.4974, Val Accuracy: 0.9598\n",
            "Epoch 850/1000, Loss: 0.4974, Val Accuracy: 0.9625\n",
            "Epoch 851/1000, Loss: 0.4974, Val Accuracy: 0.9598\n",
            "Epoch 852/1000, Loss: 0.4974, Val Accuracy: 0.9598\n",
            "Epoch 853/1000, Loss: 0.4974, Val Accuracy: 0.9598\n",
            "Epoch 854/1000, Loss: 0.4974, Val Accuracy: 0.9598\n",
            "Epoch 855/1000, Loss: 0.4974, Val Accuracy: 0.9598\n",
            "Epoch 856/1000, Loss: 0.4974, Val Accuracy: 0.9625\n",
            "Epoch 857/1000, Loss: 0.4974, Val Accuracy: 0.9598\n",
            "Epoch 858/1000, Loss: 0.4974, Val Accuracy: 0.9625\n",
            "Epoch 859/1000, Loss: 0.4974, Val Accuracy: 0.9625\n",
            "Epoch 860/1000, Loss: 0.4974, Val Accuracy: 0.9625\n",
            "Epoch 861/1000, Loss: 0.4973, Val Accuracy: 0.9625\n",
            "Epoch 862/1000, Loss: 0.4973, Val Accuracy: 0.9625\n",
            "Epoch 863/1000, Loss: 0.4973, Val Accuracy: 0.9625\n",
            "Epoch 864/1000, Loss: 0.4973, Val Accuracy: 0.9625\n",
            "Epoch 865/1000, Loss: 0.4973, Val Accuracy: 0.9625\n",
            "Epoch 866/1000, Loss: 0.4973, Val Accuracy: 0.9625\n",
            "Epoch 867/1000, Loss: 0.4973, Val Accuracy: 0.9625\n",
            "Epoch 868/1000, Loss: 0.4973, Val Accuracy: 0.9625\n",
            "Epoch 869/1000, Loss: 0.4973, Val Accuracy: 0.9598\n",
            "Epoch 870/1000, Loss: 0.4973, Val Accuracy: 0.9598\n",
            "Epoch 871/1000, Loss: 0.4973, Val Accuracy: 0.9625\n",
            "Epoch 872/1000, Loss: 0.4973, Val Accuracy: 0.9625\n",
            "Epoch 873/1000, Loss: 0.4973, Val Accuracy: 0.9625\n",
            "Epoch 874/1000, Loss: 0.4972, Val Accuracy: 0.9625\n",
            "Epoch 875/1000, Loss: 0.4972, Val Accuracy: 0.9625\n",
            "Epoch 876/1000, Loss: 0.4972, Val Accuracy: 0.9625\n",
            "Epoch 877/1000, Loss: 0.4972, Val Accuracy: 0.9625\n",
            "Epoch 878/1000, Loss: 0.4972, Val Accuracy: 0.9598\n",
            "Epoch 879/1000, Loss: 0.4972, Val Accuracy: 0.9625\n",
            "Epoch 880/1000, Loss: 0.4972, Val Accuracy: 0.9598\n",
            "Epoch 881/1000, Loss: 0.4972, Val Accuracy: 0.9625\n",
            "Epoch 882/1000, Loss: 0.4972, Val Accuracy: 0.9625\n",
            "Epoch 883/1000, Loss: 0.4972, Val Accuracy: 0.9598\n",
            "Epoch 884/1000, Loss: 0.4972, Val Accuracy: 0.9625\n",
            "Epoch 885/1000, Loss: 0.4972, Val Accuracy: 0.9598\n",
            "Epoch 886/1000, Loss: 0.4972, Val Accuracy: 0.9625\n",
            "Epoch 887/1000, Loss: 0.4972, Val Accuracy: 0.9598\n",
            "Epoch 888/1000, Loss: 0.4971, Val Accuracy: 0.9625\n",
            "Epoch 889/1000, Loss: 0.4971, Val Accuracy: 0.9598\n",
            "Epoch 890/1000, Loss: 0.4971, Val Accuracy: 0.9625\n",
            "Epoch 891/1000, Loss: 0.4971, Val Accuracy: 0.9598\n",
            "Epoch 892/1000, Loss: 0.4971, Val Accuracy: 0.9598\n",
            "Epoch 893/1000, Loss: 0.4971, Val Accuracy: 0.9598\n",
            "Epoch 894/1000, Loss: 0.4971, Val Accuracy: 0.9598\n",
            "Epoch 895/1000, Loss: 0.4971, Val Accuracy: 0.9598\n",
            "Epoch 896/1000, Loss: 0.4971, Val Accuracy: 0.9598\n",
            "Epoch 897/1000, Loss: 0.4971, Val Accuracy: 0.9625\n",
            "Epoch 898/1000, Loss: 0.4971, Val Accuracy: 0.9598\n",
            "Epoch 899/1000, Loss: 0.4971, Val Accuracy: 0.9625\n",
            "Epoch 900/1000, Loss: 0.4971, Val Accuracy: 0.9598\n",
            "Epoch 901/1000, Loss: 0.4970, Val Accuracy: 0.9625\n",
            "Epoch 902/1000, Loss: 0.4970, Val Accuracy: 0.9598\n",
            "Epoch 903/1000, Loss: 0.4970, Val Accuracy: 0.9625\n",
            "Epoch 904/1000, Loss: 0.4970, Val Accuracy: 0.9598\n",
            "Epoch 905/1000, Loss: 0.4970, Val Accuracy: 0.9598\n",
            "Epoch 906/1000, Loss: 0.4970, Val Accuracy: 0.9598\n",
            "Epoch 907/1000, Loss: 0.4970, Val Accuracy: 0.9598\n",
            "Epoch 908/1000, Loss: 0.4970, Val Accuracy: 0.9598\n",
            "Epoch 909/1000, Loss: 0.4970, Val Accuracy: 0.9625\n",
            "Epoch 910/1000, Loss: 0.4970, Val Accuracy: 0.9598\n",
            "Epoch 911/1000, Loss: 0.4970, Val Accuracy: 0.9625\n",
            "Epoch 912/1000, Loss: 0.4970, Val Accuracy: 0.9598\n",
            "Epoch 913/1000, Loss: 0.4970, Val Accuracy: 0.9625\n",
            "Epoch 914/1000, Loss: 0.4970, Val Accuracy: 0.9598\n",
            "Epoch 915/1000, Loss: 0.4969, Val Accuracy: 0.9598\n",
            "Epoch 916/1000, Loss: 0.4969, Val Accuracy: 0.9598\n",
            "Epoch 917/1000, Loss: 0.4969, Val Accuracy: 0.9598\n",
            "Epoch 918/1000, Loss: 0.4969, Val Accuracy: 0.9598\n",
            "Epoch 919/1000, Loss: 0.4969, Val Accuracy: 0.9625\n",
            "Epoch 920/1000, Loss: 0.4969, Val Accuracy: 0.9625\n",
            "Epoch 921/1000, Loss: 0.4969, Val Accuracy: 0.9625\n",
            "Epoch 922/1000, Loss: 0.4969, Val Accuracy: 0.9625\n",
            "Epoch 923/1000, Loss: 0.4969, Val Accuracy: 0.9625\n",
            "Epoch 924/1000, Loss: 0.4969, Val Accuracy: 0.9625\n",
            "Epoch 925/1000, Loss: 0.4969, Val Accuracy: 0.9625\n",
            "Epoch 926/1000, Loss: 0.4969, Val Accuracy: 0.9625\n",
            "Epoch 927/1000, Loss: 0.4969, Val Accuracy: 0.9625\n",
            "Epoch 928/1000, Loss: 0.4969, Val Accuracy: 0.9625\n",
            "Epoch 929/1000, Loss: 0.4969, Val Accuracy: 0.9625\n",
            "Epoch 930/1000, Loss: 0.4968, Val Accuracy: 0.9625\n",
            "Epoch 931/1000, Loss: 0.4968, Val Accuracy: 0.9625\n",
            "Epoch 932/1000, Loss: 0.4968, Val Accuracy: 0.9598\n",
            "Epoch 933/1000, Loss: 0.4968, Val Accuracy: 0.9598\n",
            "Epoch 934/1000, Loss: 0.4968, Val Accuracy: 0.9598\n",
            "Epoch 935/1000, Loss: 0.4968, Val Accuracy: 0.9598\n",
            "Epoch 936/1000, Loss: 0.4968, Val Accuracy: 0.9598\n",
            "Epoch 937/1000, Loss: 0.4968, Val Accuracy: 0.9625\n",
            "Epoch 938/1000, Loss: 0.4968, Val Accuracy: 0.9598\n",
            "Epoch 939/1000, Loss: 0.4968, Val Accuracy: 0.9598\n",
            "Epoch 940/1000, Loss: 0.4968, Val Accuracy: 0.9598\n",
            "Epoch 941/1000, Loss: 0.4968, Val Accuracy: 0.9598\n",
            "Epoch 942/1000, Loss: 0.4968, Val Accuracy: 0.9625\n",
            "Epoch 943/1000, Loss: 0.4968, Val Accuracy: 0.9625\n",
            "Epoch 944/1000, Loss: 0.4967, Val Accuracy: 0.9625\n",
            "Epoch 945/1000, Loss: 0.4967, Val Accuracy: 0.9625\n",
            "Epoch 946/1000, Loss: 0.4967, Val Accuracy: 0.9625\n",
            "Epoch 947/1000, Loss: 0.4967, Val Accuracy: 0.9625\n",
            "Epoch 948/1000, Loss: 0.4967, Val Accuracy: 0.9625\n",
            "Epoch 949/1000, Loss: 0.4967, Val Accuracy: 0.9625\n",
            "Epoch 950/1000, Loss: 0.4967, Val Accuracy: 0.9625\n",
            "Epoch 951/1000, Loss: 0.4967, Val Accuracy: 0.9625\n",
            "Epoch 952/1000, Loss: 0.4967, Val Accuracy: 0.9625\n",
            "Epoch 953/1000, Loss: 0.4967, Val Accuracy: 0.9625\n",
            "Epoch 954/1000, Loss: 0.4967, Val Accuracy: 0.9625\n",
            "Epoch 955/1000, Loss: 0.4967, Val Accuracy: 0.9598\n",
            "Epoch 956/1000, Loss: 0.4967, Val Accuracy: 0.9625\n",
            "Epoch 957/1000, Loss: 0.4967, Val Accuracy: 0.9625\n",
            "Epoch 958/1000, Loss: 0.4966, Val Accuracy: 0.9625\n",
            "Epoch 959/1000, Loss: 0.4966, Val Accuracy: 0.9598\n",
            "Epoch 960/1000, Loss: 0.4966, Val Accuracy: 0.9625\n",
            "Epoch 961/1000, Loss: 0.4966, Val Accuracy: 0.9598\n",
            "Epoch 962/1000, Loss: 0.4966, Val Accuracy: 0.9625\n",
            "Epoch 963/1000, Loss: 0.4966, Val Accuracy: 0.9598\n",
            "Epoch 964/1000, Loss: 0.4966, Val Accuracy: 0.9625\n",
            "Epoch 965/1000, Loss: 0.4966, Val Accuracy: 0.9625\n",
            "Epoch 966/1000, Loss: 0.4966, Val Accuracy: 0.9625\n",
            "Epoch 967/1000, Loss: 0.4966, Val Accuracy: 0.9598\n",
            "Epoch 968/1000, Loss: 0.4966, Val Accuracy: 0.9625\n",
            "Epoch 969/1000, Loss: 0.4966, Val Accuracy: 0.9598\n",
            "Epoch 970/1000, Loss: 0.4966, Val Accuracy: 0.9625\n",
            "Epoch 971/1000, Loss: 0.4966, Val Accuracy: 0.9625\n",
            "Epoch 972/1000, Loss: 0.4965, Val Accuracy: 0.9625\n",
            "Epoch 973/1000, Loss: 0.4965, Val Accuracy: 0.9625\n",
            "Epoch 974/1000, Loss: 0.4965, Val Accuracy: 0.9625\n",
            "Epoch 975/1000, Loss: 0.4965, Val Accuracy: 0.9625\n",
            "Epoch 976/1000, Loss: 0.4965, Val Accuracy: 0.9625\n",
            "Epoch 977/1000, Loss: 0.4965, Val Accuracy: 0.9625\n",
            "Epoch 978/1000, Loss: 0.4965, Val Accuracy: 0.9625\n",
            "Epoch 979/1000, Loss: 0.4965, Val Accuracy: 0.9625\n",
            "Epoch 980/1000, Loss: 0.4965, Val Accuracy: 0.9625\n",
            "Epoch 981/1000, Loss: 0.4965, Val Accuracy: 0.9625\n",
            "Epoch 982/1000, Loss: 0.4965, Val Accuracy: 0.9625\n",
            "Epoch 983/1000, Loss: 0.4965, Val Accuracy: 0.9598\n",
            "Epoch 984/1000, Loss: 0.4965, Val Accuracy: 0.9598\n",
            "Epoch 985/1000, Loss: 0.4965, Val Accuracy: 0.9598\n",
            "Epoch 986/1000, Loss: 0.4965, Val Accuracy: 0.9598\n",
            "Epoch 987/1000, Loss: 0.4964, Val Accuracy: 0.9625\n",
            "Epoch 988/1000, Loss: 0.4964, Val Accuracy: 0.9625\n",
            "Epoch 989/1000, Loss: 0.4964, Val Accuracy: 0.9625\n",
            "Epoch 990/1000, Loss: 0.4964, Val Accuracy: 0.9625\n",
            "Epoch 991/1000, Loss: 0.4964, Val Accuracy: 0.9625\n",
            "Epoch 992/1000, Loss: 0.4964, Val Accuracy: 0.9625\n",
            "Epoch 993/1000, Loss: 0.4964, Val Accuracy: 0.9625\n",
            "Epoch 994/1000, Loss: 0.4964, Val Accuracy: 0.9625\n",
            "Epoch 995/1000, Loss: 0.4964, Val Accuracy: 0.9625\n",
            "Epoch 996/1000, Loss: 0.4964, Val Accuracy: 0.9625\n",
            "Epoch 997/1000, Loss: 0.4964, Val Accuracy: 0.9598\n",
            "Epoch 998/1000, Loss: 0.4964, Val Accuracy: 0.9625\n",
            "Epoch 999/1000, Loss: 0.4964, Val Accuracy: 0.9598\n",
            "Epoch 1000/1000, Loss: 0.4964, Val Accuracy: 0.9598\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ScrflNMP8qQW"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyO7QPAPKKe7j1w1lnmIIy/0",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}